{
  "trial_id": "trial_1_12",
  "generation": 1,
  "parent_id": null,
  "code": "import numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.spatial.distance import pdist, squareform\n\nclass CMAES:\n    def __init__(self, xmean, sigma, lam):\n        self.dim = len(xmean)\n        self.pop_size = lam\n        self.mu = lam // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.mueff = 1 / np.sum(self.weights**2)\n        \n        self.xmean = xmean\n        self.sigma = sigma\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.B = np.eye(self.dim)\n        self.D = np.ones(self.dim)\n        \n        # Strategy parameters\n        self.cc = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.cmu = min(1 - self.c1, 2 * (self.mueff - 2 + 1 / self.mueff) / ((self.dim + 2)**2 + self.mueff))\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.cs\n        self.chiN = np.sqrt(self.dim) * (1 - 1 / (4 * self.dim) + 1 / (21 * self.dim**2))\n        \n        self.counteval = 0\n        self.eigeneval = 0\n\n    def ask(self):\n        # Eigendecomposition\n        if self.counteval - self.eigeneval > self.pop_size / (self.c1 + self.cmu) / self.dim / 10:\n            self.eigeneval = self.counteval\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            try:\n                D, B = np.linalg.eigh(self.C)\n                if np.any(D <= 0):\n                    D = np.maximum(D, 1e-10)\n                self.D = np.sqrt(D)\n                self.B = B\n            except np.linalg.LinAlgError:\n                pass # Keep old B, D if decomposition fails\n\n        self.z = np.random.randn(self.pop_size, self.dim)\n        self.y = self.B @ (self.D[:, None] * self.z.T)\n        self.x = self.xmean + self.sigma * self.y.T\n        return self.x\n\n    def tell(self, fitnesses):\n        # Sort by fitness and compute weighted mean\n        idx = np.argsort(fitnesses)\n        self.x = self.x[idx]\n        self.z = self.z[idx]\n        self.y = self.y.T[:, idx] \n        \n        xold = self.xmean\n        self.xmean = np.dot(self.x[:self.mu].T, self.weights)\n        \n        zmean = np.dot(self.z[:self.mu].T, self.weights)\n        ymean = np.dot(self.y[:, :self.mu], self.weights)\n        \n        # Evolution paths\n        self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (self.B @ zmean)\n        \n        hsig = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (self.counteval / self.pop_size + 1))) / self.chiN < 1.4 + 2 / (self.dim + 1)\n        self.pc = (1 - self.cc) * self.pc + hsig * np.sqrt(self.cc * (2 - self.cc) * self.mueff) * ymean\n        \n        # Covariance matrix update\n        artmp = (1 / self.sigma) * (self.x[:self.mu].T - xold[:, None])\n        \n        self.C = (1 - self.c1 - self.cmu) * self.C + \\\n                 self.c1 * (np.outer(self.pc, self.pc) + (1 - hsig) * self.cc * (2 - self.cc) * self.C) + \\\n                 self.cmu * np.dot(artmp, np.dot(np.diag(self.weights), artmp.T))\n        \n        # Step size update\n        self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n        self.counteval += self.pop_size\n\ndef get_radius(flat_coords):\n    N = len(flat_coords) // 2\n    pts = flat_coords.reshape((N, 2))\n    # Wall distances\n    d_walls = np.min(np.hstack([pts, 1 - pts]), axis=1)\n    # Pairwise distances\n    if N > 1:\n        d_pairs = pdist(pts)\n        r = np.min(np.hstack([d_pairs / 2.0, d_walls]))\n    else:\n        r = np.min(d_walls)\n    return max(0.0, r)\n\ndef cma_objective(flat_coords):\n    # Penalize out of bounds [0,1]\n    penalty = 0\n    pts = flat_coords.reshape((-1, 2))\n    \n    # Soft constraints for CMA-ES exploration\n    out_of_bounds = np.sum(pts < 0) + np.sum(pts > 1)\n    if out_of_bounds > 0:\n        # Distance to box\n        dist_out = np.sum(np.maximum(0, -pts) ** 2 + np.maximum(0, pts - 1) ** 2)\n        penalty = 100 + dist_out * 1000\n        \n    pts_clipped = np.clip(pts, 0, 1)\n    r = get_radius(pts_clipped.flatten())\n    return -r + penalty\n\ndef construct_packing():\n    N = 26\n    dim = N * 2\n    \n    # CMA-ES Parameters\n    # Initialize randomly\n    x0 = np.random.rand(dim)\n    sigma0 = 0.2\n    pop_size = 24 # 4 + 3*log(52) approx 16, using slightly more\n    \n    es = CMAES(x0, sigma0, pop_size)\n    \n    # Run CMA-ES\n    generations = 250\n    best_fitness = float('inf')\n    best_x = x0\n    \n    for gen in range(generations):\n        pop = es.ask()\n        fitnesses = np.array([cma_objective(ind) for ind in pop])\n        es.tell(fitnesses)\n        \n        min_fit = np.min(fitnesses)\n        if min_fit < best_fitness:\n            best_fitness = min_fit\n            best_x = pop[np.argmin(fitnesses)]\n            \n        # Convergence check (simple)\n        if es.sigma < 1e-4:\n            break\n\n    # Extract best approximate solution\n    x_approx = np.clip(best_x, 0, 1)\n    \n    # Polish with SLSQP to maximize radius exactly\n    # Variables: coords (52) + radius (1) -> 53 vars\n    x_init = np.append(x_approx, get_radius(x_approx))\n    \n    def polish_obj(params):\n        return -params[-1] # Maximize r\n    \n    # Constraints\n    # 1. x_i - r >= 0\n    # 2. 1 - x_i - r >= 0\n    # 3. dist_ij^2 - (2r)^2 >= 0\n    \n    cons = []\n    # Wall constraints\n    # x >= r -> x - r >= 0\n    # x <= 1-r -> 1 - x - r >= 0\n    # We can express this as bounds on x depending on r, but SLSQP handles general constraints better as list\n    \n    # Precompute indices for pairwise\n    idx_pairs = []\n    for i in range(N):\n        for j in range(i + 1, N):\n            idx_pairs.append((i, j))\n            \n    def constraint_walls(params):\n        coords = params[:-1].reshape((N, 2))\n        r = params[-1]\n        # min(coords) - r >= 0\n        # 1 - max(coords) - r >= 0\n        return np.hstack([\n            (coords - r).flatten(),\n            (1 - coords - r).flatten()\n        ])\n        \n    def constraint_dist(params):\n        coords = params[:-1].reshape((N, 2))\n        r = params[-1]\n        # Calculate squared distances\n        # diffs = coords[idx_i] - coords[idx_j]\n        # dists2 = sum(diffs**2)\n        # dists2 - 4r^2 >= 0\n        p = coords\n        d2 = pdist(p, 'sqeuclidean')\n        return d2 - 4 * r * r\n\n    cons = [\n        {'type': 'ineq', 'fun': constraint_walls},\n        {'type': 'ineq', 'fun': constraint_dist}\n    ]\n    \n    # Bounds for x in [0,1], r in [0, 0.5]\n    bounds = [(0, 1)] * dim + [(0, 0.5)]\n    \n    res = minimize(polish_obj, x_init, method='SLSQP', bounds=bounds, constraints=cons, \n                   options={'maxiter': 500, 'ftol': 1e-6})\n    \n    final_params = res.x\n    final_centers = final_params[:-1].reshape((N, 2))\n    final_r = final_params[-1]\n    \n    # Ensure strict validity\n    # Re-calculate max valid r for these centers to be safe against numerical slack\n    valid_r = get_radius(final_centers.flatten())\n    \n    # Although optimization tried to push r, valid_r is the ground truth for non-overlap\n    radii = np.full(N, valid_r)\n    \n    return final_centers, radii, np.sum(radii)\n\ndef run_packing():\n    return construct_packing()",
  "metrics": {
    "valid": false,
    "score": 0.0,
    "eval_time": 0.32961106300354004,
    "error": "ValueError: operands could not be broadcast together with shapes (52,) (24,) "
  },
  "prompt": "Solve the circle packing problem (26 circles). \n\nStrategy: **CMA-ES (Covariance Matrix Adaptation)**.\n- Use `cma` library if available, or implement a simple version/use `scipy.optimize.minimize` with a strategy that mimics it (e.g., random restarts with variance adaptation).\n- Since we can't install packages, simulate the logic: Sample a population of packings from a multivariate normal distribution, select best, update mean and covariance.\n\nIMPORTANT: Output ONLY the Python code in a ```python``` block. Do not add explanations or text outside the block.",
  "response": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.spatial.distance import pdist, squareform\n\nclass CMAES:\n    def __init__(self, xmean, sigma, lam):\n        self.dim = len(xmean)\n        self.pop_size = lam\n        self.mu = lam // 2\n        self.weights = np.log(self.mu + 0.5) - np.log(np.arange(1, self.mu + 1))\n        self.weights /= np.sum(self.weights)\n        self.mueff = 1 / np.sum(self.weights**2)\n        \n        self.xmean = xmean\n        self.sigma = sigma\n        self.C = np.eye(self.dim)\n        self.pc = np.zeros(self.dim)\n        self.ps = np.zeros(self.dim)\n        self.B = np.eye(self.dim)\n        self.D = np.ones(self.dim)\n        \n        # Strategy parameters\n        self.cc = (4 + self.mueff / self.dim) / (self.dim + 4 + 2 * self.mueff / self.dim)\n        self.cs = (self.mueff + 2) / (self.dim + self.mueff + 5)\n        self.c1 = 2 / ((self.dim + 1.3)**2 + self.mueff)\n        self.cmu = min(1 - self.c1, 2 * (self.mueff - 2 + 1 / self.mueff) / ((self.dim + 2)**2 + self.mueff))\n        self.damps = 1 + 2 * max(0, np.sqrt((self.mueff - 1) / (self.dim + 1)) - 1) + self.cs\n        self.chiN = np.sqrt(self.dim) * (1 - 1 / (4 * self.dim) + 1 / (21 * self.dim**2))\n        \n        self.counteval = 0\n        self.eigeneval = 0\n\n    def ask(self):\n        # Eigendecomposition\n        if self.counteval - self.eigeneval > self.pop_size / (self.c1 + self.cmu) / self.dim / 10:\n            self.eigeneval = self.counteval\n            self.C = np.triu(self.C) + np.triu(self.C, 1).T\n            try:\n                D, B = np.linalg.eigh(self.C)\n                if np.any(D <= 0):\n                    D = np.maximum(D, 1e-10)\n                self.D = np.sqrt(D)\n                self.B = B\n            except np.linalg.LinAlgError:\n                pass # Keep old B, D if decomposition fails\n\n        self.z = np.random.randn(self.pop_size, self.dim)\n        self.y = self.B @ (self.D[:, None] * self.z.T)\n        self.x = self.xmean + self.sigma * self.y.T\n        return self.x\n\n    def tell(self, fitnesses):\n        # Sort by fitness and compute weighted mean\n        idx = np.argsort(fitnesses)\n        self.x = self.x[idx]\n        self.z = self.z[idx]\n        self.y = self.y.T[:, idx] \n        \n        xold = self.xmean\n        self.xmean = np.dot(self.x[:self.mu].T, self.weights)\n        \n        zmean = np.dot(self.z[:self.mu].T, self.weights)\n        ymean = np.dot(self.y[:, :self.mu], self.weights)\n        \n        # Evolution paths\n        self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * (self.B @ zmean)\n        \n        hsig = np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (self.counteval / self.pop_size + 1))) / self.chiN < 1.4 + 2 / (self.dim + 1)\n        self.pc = (1 - self.cc) * self.pc + hsig * np.sqrt(self.cc * (2 - self.cc) * self.mueff) * ymean\n        \n        # Covariance matrix update\n        artmp = (1 / self.sigma) * (self.x[:self.mu].T - xold[:, None])\n        \n        self.C = (1 - self.c1 - self.cmu) * self.C + \\\n                 self.c1 * (np.outer(self.pc, self.pc) + (1 - hsig) * self.cc * (2 - self.cc) * self.C) + \\\n                 self.cmu * np.dot(artmp, np.dot(np.diag(self.weights), artmp.T))\n        \n        # Step size update\n        self.sigma *= np.exp((self.cs / self.damps) * (np.linalg.norm(self.ps) / self.chiN - 1))\n        self.counteval += self.pop_size\n\ndef get_radius(flat_coords):\n    N = len(flat_coords) // 2\n    pts = flat_coords.reshape((N, 2))\n    # Wall distances\n    d_walls = np.min(np.hstack([pts, 1 - pts]), axis=1)\n    # Pairwise distances\n    if N > 1:\n        d_pairs = pdist(pts)\n        r = np.min(np.hstack([d_pairs / 2.0, d_walls]))\n    else:\n        r = np.min(d_walls)\n    return max(0.0, r)\n\ndef cma_objective(flat_coords):\n    # Penalize out of bounds [0,1]\n    penalty = 0\n    pts = flat_coords.reshape((-1, 2))\n    \n    # Soft constraints for CMA-ES exploration\n    out_of_bounds = np.sum(pts < 0) + np.sum(pts > 1)\n    if out_of_bounds > 0:\n        # Distance to box\n        dist_out = np.sum(np.maximum(0, -pts) ** 2 + np.maximum(0, pts - 1) ** 2)\n        penalty = 100 + dist_out * 1000\n        \n    pts_clipped = np.clip(pts, 0, 1)\n    r = get_radius(pts_clipped.flatten())\n    return -r + penalty\n\ndef construct_packing():\n    N = 26\n    dim = N * 2\n    \n    # CMA-ES Parameters\n    # Initialize randomly\n    x0 = np.random.rand(dim)\n    sigma0 = 0.2\n    pop_size = 24 # 4 + 3*log(52) approx 16, using slightly more\n    \n    es = CMAES(x0, sigma0, pop_size)\n    \n    # Run CMA-ES\n    generations = 250\n    best_fitness = float('inf')\n    best_x = x0\n    \n    for gen in range(generations):\n        pop = es.ask()\n        fitnesses = np.array([cma_objective(ind) for ind in pop])\n        es.tell(fitnesses)\n        \n        min_fit = np.min(fitnesses)\n        if min_fit < best_fitness:\n            best_fitness = min_fit\n            best_x = pop[np.argmin(fitnesses)]\n            \n        # Convergence check (simple)\n        if es.sigma < 1e-4:\n            break\n\n    # Extract best approximate solution\n    x_approx = np.clip(best_x, 0, 1)\n    \n    # Polish with SLSQP to maximize radius exactly\n    # Variables: coords (52) + radius (1) -> 53 vars\n    x_init = np.append(x_approx, get_radius(x_approx))\n    \n    def polish_obj(params):\n        return -params[-1] # Maximize r\n    \n    # Constraints\n    # 1. x_i - r >= 0\n    # 2. 1 - x_i - r >= 0\n    # 3. dist_ij^2 - (2r)^2 >= 0\n    \n    cons = []\n    # Wall constraints\n    # x >= r -> x - r >= 0\n    # x <= 1-r -> 1 - x - r >= 0\n    # We can express this as bounds on x depending on r, but SLSQP handles general constraints better as list\n    \n    # Precompute indices for pairwise\n    idx_pairs = []\n    for i in range(N):\n        for j in range(i + 1, N):\n            idx_pairs.append((i, j))\n            \n    def constraint_walls(params):\n        coords = params[:-1].reshape((N, 2))\n        r = params[-1]\n        # min(coords) - r >= 0\n        # 1 - max(coords) - r >= 0\n        return np.hstack([\n            (coords - r).flatten(),\n            (1 - coords - r).flatten()\n        ])\n        \n    def constraint_dist(params):\n        coords = params[:-1].reshape((N, 2))\n        r = params[-1]\n        # Calculate squared distances\n        # diffs = coords[idx_i] - coords[idx_j]\n        # dists2 = sum(diffs**2)\n        # dists2 - 4r^2 >= 0\n        p = coords\n        d2 = pdist(p, 'sqeuclidean')\n        return d2 - 4 * r * r\n\n    cons = [\n        {'type': 'ineq', 'fun': constraint_walls},\n        {'type': 'ineq', 'fun': constraint_dist}\n    ]\n    \n    # Bounds for x in [0,1], r in [0, 0.5]\n    bounds = [(0, 1)] * dim + [(0, 0.5)]\n    \n    res = minimize(polish_obj, x_init, method='SLSQP', bounds=bounds, constraints=cons, \n                   options={'maxiter': 500, 'ftol': 1e-6})\n    \n    final_params = res.x\n    final_centers = final_params[:-1].reshape((N, 2))\n    final_r = final_params[-1]\n    \n    # Ensure strict validity\n    # Re-calculate max valid r for these centers to be safe against numerical slack\n    valid_r = get_radius(final_centers.flatten())\n    \n    # Although optimization tried to push r, valid_r is the ground truth for non-overlap\n    radii = np.full(N, valid_r)\n    \n    return final_centers, radii, np.sum(radii)\n\ndef run_packing():\n    return construct_packing()\n```",
  "reasoning": "",
  "timestamp": "2026-01-08T10:16:56.738054",
  "cost_data": null,
  "model_config": {
    "model": "gemini-3-pro-preview",
    "temperature": 0.7,
    "provider_debug": {
      "finish_reason": "STOP",
      "usage_metadata": {
        "prompt_token_count": 350,
        "candidates_token_count": 2704,
        "thoughts_token_count": 8268
      },
      "response_text_len": 7361
    }
  }
}