{
  "trial_id": "trial_18_3",
  "generation": 18,
  "parent_id": "trial_13_9",
  "code": "import numpy as np\nfrom scipy.optimize import minimize, basinhopping\n\ndef construct_packing():\n    N = 26\n    \n    # Indices for pairwise constraints\n    idx_i, idx_j = np.triu_indices(N, k=1)\n    num_pairs = len(idx_i)\n    \n    # Initial configuration: Staggered rows (approx hexagonal)\n    # 5 rows: 5, 6, 5, 5, 5 = 26\n    # Or 5, 5, 6, 5, 5\n    x0 = np.zeros(3 * N)\n    \n    # Layout strategy: Place in rows\n    rows = [5, 6, 5, 5, 5]\n    y_levels = np.linspace(0.1, 0.9, len(rows))\n    \n    cnt = 0\n    for r_idx, count in enumerate(rows):\n        y_val = y_levels[r_idx]\n        x_vals = np.linspace(0.1, 0.9, count)\n        for k in range(count):\n            x0[3*cnt] = x_vals[k]      # x\n            x0[3*cnt+1] = y_val        # y\n            x0[3*cnt+2] = 0.05         # r (small initial radius)\n            cnt += 1\n            \n    # Objective: Maximize sum of radii\n    def objective(p):\n        return -np.sum(p[2::3])\n\n    def objective_grad(p):\n        grad = np.zeros_like(p)\n        grad[2::3] = -1.0\n        return grad\n\n    # Constraints\n    # 1. Box constraints (linear) -> Handled by bounds mostly, but r depends on x,y\n    #    0 <= x_i - r_i  => r_i - x_i <= 0\n    #    x_i + r_i <= 1  => x_i + r_i - 1 <= 0\n    #    0 <= y_i - r_i\n    #    y_i + r_i <= 1\n    #    These are 4 * N constraints.\n    \n    # 2. Overlap constraints (nonlinear)\n    #    (xi - xj)^2 + (yi - yj)^2 >= (ri + rj)^2\n    \n    def constraints(p):\n        x = p[0::3]\n        y = p[1::3]\n        r = p[2::3]\n        \n        # Wall constraints (inequality: val >= 0)\n        c_left   = x - r\n        c_right  = 1.0 - (x + r)\n        c_bottom = y - r\n        c_top    = 1.0 - (y + r)\n        \n        # Pair constraints\n        dx = x[idx_i] - x[idx_j]\n        dy = y[idx_i] - y[idx_j]\n        sr = r[idx_i] + r[idx_j]\n        c_pair = dx**2 + dy**2 - sr**2\n        \n        return np.concatenate([c_left, c_right, c_bottom, c_top, c_pair])\n\n    def constraints_jac(p):\n        x = p[0::3]\n        y = p[1::3]\n        r = p[2::3]\n        \n        n_vars = 3 * N\n        n_walls = 4 * N\n        n_pairs = num_pairs\n        total_cons = n_walls + n_pairs\n        \n        jac = np.zeros((total_cons, n_vars))\n        \n        # Wall constraints gradients\n        # c_left = x - r >= 0. d/dx=1, d/dr=-1\n        # c_right = 1 - x - r >= 0. d/dx=-1, d/dr=-1\n        # c_bottom = y - r >= 0. d/dy=1, d/dr=-1\n        # c_top = 1 - y - r >= 0. d/dy=-1, d/dr=-1\n        \n        eye = np.eye(N)\n        \n        # Fill wall parts\n        # Order in constraints: left, right, bottom, top\n        # x indices: 0::3, y indices: 1::3, r indices: 2::3\n        \n        # Left: x_i - r_i\n        jac[0:N, 0::3] = eye\n        jac[0:N, 2::3] = -eye\n        \n        # Right: 1 - x_i - r_i\n        jac[N:2*N, 0::3] = -eye\n        jac[N:2*N, 2::3] = -eye\n        \n        # Bottom: y_i - r_i\n        jac[2*N:3*N, 1::3] = eye\n        jac[2*N:3*N, 2::3] = -eye\n        \n        # Top: 1 - y_i - r_i\n        jac[3*N:4*N, 1::3] = -eye\n        jac[3*N:4*N, 2::3] = -eye\n        \n        # Pair constraints\n        # g = (xi-xj)^2 + (yi-yj)^2 - (ri+rj)^2\n        dx = x[idx_i] - x[idx_j]\n        dy = y[idx_i] - y[idx_j]\n        sr = r[idx_i] + r[idx_j]\n        \n        # Derivatives\n        # w.r.t xi: 2*dx\n        # w.r.t xj: -2*dx\n        # w.r.t yi: 2*dy\n        # w.r.t yj: -2*dy\n        # w.r.t ri: -2*sr\n        # w.r.t rj: -2*sr\n        \n        rows_start = 4 * N\n        \n        # We can use advanced indexing for speed\n        # For each pair k (connecting i and j):\n        # jac[rows_start + k, 3*i] = ...\n        \n        # Construct indices for sparse-like assignment\n        k_indices = np.arange(num_pairs)\n        \n        # x gradients\n        jac[rows_start + k_indices, 3 * idx_i] = 2 * dx\n        jac[rows_start + k_indices, 3 * idx_j] = -2 * dx\n        \n        # y gradients\n        jac[rows_start + k_indices, 3 * idx_i + 1] = 2 * dy\n        jac[rows_start + k_indices, 3 * idx_j + 1] = -2 * dy\n        \n        # r gradients\n        jac[rows_start + k_indices, 3 * idx_i + 2] = -2 * sr\n        jac[rows_start + k_indices, 3 * idx_j + 2] = -2 * sr\n        \n        return jac\n\n    # Bounds: x,y in [0,1], r in [0, 0.5]\n    bounds = []\n    for i in range(N):\n        bounds.append((0, 1))    # x\n        bounds.append((0, 1))    # y\n        bounds.append((0, 0.5))  # r\n        \n    # Define the local minimization dictionary\n    cons = {'type': 'ineq', 'fun': constraints, 'jac': constraints_jac}\n    minimizer_kwargs = {\n        'method': 'SLSQP',\n        'jac': objective_grad,\n        'constraints': cons,\n        'bounds': bounds,\n        'options': {'maxiter': 100, 'ftol': 1e-6, 'disp': False}\n    }\n\n    # Custom step taking for Basin Hopping\n    class RandomDisplacement:\n        def __init__(self, stepsize=0.05):\n            self.stepsize = stepsize\n            \n        def __call__(self, x):\n            # Perturb x and y, keep r small or perturb slightly\n            # x structure: x, y, r, x, y, r...\n            s = self.stepsize\n            perturbation = np.random.uniform(-s, s, x.shape)\n            # Apply mainly to positions\n            mask = np.tile([1, 1, 0.1], N) # Less perturbation on radii\n            x_new = x + perturbation * mask\n            # Clip to bounds\n            x_new = np.clip(x_new, 0, 1)\n            # Ensure r is positive\n            x_new[2::3] = np.abs(x_new[2::3])\n            return x_new\n\n    # Run Basin Hopping\n    # T=0.002, niter=100 as requested\n    take_step = RandomDisplacement(stepsize=0.05)\n    \n    # First, run a quick optimization to get a valid start from the grid\n    res_start = minimize(objective, x0, jac=objective_grad, method='SLSQP', \n                         bounds=bounds, constraints=cons, options={'maxiter': 50})\n    x_start = res_start.x\n\n    # Run global optimization\n    res = basinhopping(objective, x_start, niter=100, T=0.002, \n                       minimizer_kwargs=minimizer_kwargs, take_step=take_step,\n                       seed=42)\n    \n    # Final refinement\n    res_final = minimize(objective, res.x, jac=objective_grad, method='SLSQP',\n                         bounds=bounds, constraints=cons, \n                         options={'maxiter': 500, 'ftol': 1e-9})\n    \n    p_opt = res_final.x\n    centers = np.vstack((p_opt[0::3], p_opt[1::3])).T\n    radii = p_opt[2::3]\n    total_r = np.sum(radii)\n    \n    return centers, radii, total_r\n\ndef run_packing():\n    return construct_packing()",
  "metrics": {
    "valid": true,
    "score": 2.635983084917486,
    "eval_time": 4.40227198600769,
    "error": null
  },
  "prompt": "System: Output ONLY Python code. Refine {CODE_TRIAL_13_9}. \n\nStrategy: **Constructive Basin Hopping**. \n- The parent code has a good geometric structure.\n- Apply the `scipy.optimize.basinhopping` logic to this specific initial configuration.\n- Use `niter=100`, `T=0.002`.\n\nCRITICAL: Output ONLY a single Python code block starting with ```python and ending with ```. Do not write any text before or after the block.",
  "response": "```python\nimport numpy as np\nfrom scipy.optimize import minimize, basinhopping\n\ndef construct_packing():\n    N = 26\n    \n    # Indices for pairwise constraints\n    idx_i, idx_j = np.triu_indices(N, k=1)\n    num_pairs = len(idx_i)\n    \n    # Initial configuration: Staggered rows (approx hexagonal)\n    # 5 rows: 5, 6, 5, 5, 5 = 26\n    # Or 5, 5, 6, 5, 5\n    x0 = np.zeros(3 * N)\n    \n    # Layout strategy: Place in rows\n    rows = [5, 6, 5, 5, 5]\n    y_levels = np.linspace(0.1, 0.9, len(rows))\n    \n    cnt = 0\n    for r_idx, count in enumerate(rows):\n        y_val = y_levels[r_idx]\n        x_vals = np.linspace(0.1, 0.9, count)\n        for k in range(count):\n            x0[3*cnt] = x_vals[k]      # x\n            x0[3*cnt+1] = y_val        # y\n            x0[3*cnt+2] = 0.05         # r (small initial radius)\n            cnt += 1\n            \n    # Objective: Maximize sum of radii\n    def objective(p):\n        return -np.sum(p[2::3])\n\n    def objective_grad(p):\n        grad = np.zeros_like(p)\n        grad[2::3] = -1.0\n        return grad\n\n    # Constraints\n    # 1. Box constraints (linear) -> Handled by bounds mostly, but r depends on x,y\n    #    0 <= x_i - r_i  => r_i - x_i <= 0\n    #    x_i + r_i <= 1  => x_i + r_i - 1 <= 0\n    #    0 <= y_i - r_i\n    #    y_i + r_i <= 1\n    #    These are 4 * N constraints.\n    \n    # 2. Overlap constraints (nonlinear)\n    #    (xi - xj)^2 + (yi - yj)^2 >= (ri + rj)^2\n    \n    def constraints(p):\n        x = p[0::3]\n        y = p[1::3]\n        r = p[2::3]\n        \n        # Wall constraints (inequality: val >= 0)\n        c_left   = x - r\n        c_right  = 1.0 - (x + r)\n        c_bottom = y - r\n        c_top    = 1.0 - (y + r)\n        \n        # Pair constraints\n        dx = x[idx_i] - x[idx_j]\n        dy = y[idx_i] - y[idx_j]\n        sr = r[idx_i] + r[idx_j]\n        c_pair = dx**2 + dy**2 - sr**2\n        \n        return np.concatenate([c_left, c_right, c_bottom, c_top, c_pair])\n\n    def constraints_jac(p):\n        x = p[0::3]\n        y = p[1::3]\n        r = p[2::3]\n        \n        n_vars = 3 * N\n        n_walls = 4 * N\n        n_pairs = num_pairs\n        total_cons = n_walls + n_pairs\n        \n        jac = np.zeros((total_cons, n_vars))\n        \n        # Wall constraints gradients\n        # c_left = x - r >= 0. d/dx=1, d/dr=-1\n        # c_right = 1 - x - r >= 0. d/dx=-1, d/dr=-1\n        # c_bottom = y - r >= 0. d/dy=1, d/dr=-1\n        # c_top = 1 - y - r >= 0. d/dy=-1, d/dr=-1\n        \n        eye = np.eye(N)\n        \n        # Fill wall parts\n        # Order in constraints: left, right, bottom, top\n        # x indices: 0::3, y indices: 1::3, r indices: 2::3\n        \n        # Left: x_i - r_i\n        jac[0:N, 0::3] = eye\n        jac[0:N, 2::3] = -eye\n        \n        # Right: 1 - x_i - r_i\n        jac[N:2*N, 0::3] = -eye\n        jac[N:2*N, 2::3] = -eye\n        \n        # Bottom: y_i - r_i\n        jac[2*N:3*N, 1::3] = eye\n        jac[2*N:3*N, 2::3] = -eye\n        \n        # Top: 1 - y_i - r_i\n        jac[3*N:4*N, 1::3] = -eye\n        jac[3*N:4*N, 2::3] = -eye\n        \n        # Pair constraints\n        # g = (xi-xj)^2 + (yi-yj)^2 - (ri+rj)^2\n        dx = x[idx_i] - x[idx_j]\n        dy = y[idx_i] - y[idx_j]\n        sr = r[idx_i] + r[idx_j]\n        \n        # Derivatives\n        # w.r.t xi: 2*dx\n        # w.r.t xj: -2*dx\n        # w.r.t yi: 2*dy\n        # w.r.t yj: -2*dy\n        # w.r.t ri: -2*sr\n        # w.r.t rj: -2*sr\n        \n        rows_start = 4 * N\n        \n        # We can use advanced indexing for speed\n        # For each pair k (connecting i and j):\n        # jac[rows_start + k, 3*i] = ...\n        \n        # Construct indices for sparse-like assignment\n        k_indices = np.arange(num_pairs)\n        \n        # x gradients\n        jac[rows_start + k_indices, 3 * idx_i] = 2 * dx\n        jac[rows_start + k_indices, 3 * idx_j] = -2 * dx\n        \n        # y gradients\n        jac[rows_start + k_indices, 3 * idx_i + 1] = 2 * dy\n        jac[rows_start + k_indices, 3 * idx_j + 1] = -2 * dy\n        \n        # r gradients\n        jac[rows_start + k_indices, 3 * idx_i + 2] = -2 * sr\n        jac[rows_start + k_indices, 3 * idx_j + 2] = -2 * sr\n        \n        return jac\n\n    # Bounds: x,y in [0,1], r in [0, 0.5]\n    bounds = []\n    for i in range(N):\n        bounds.append((0, 1))    # x\n        bounds.append((0, 1))    # y\n        bounds.append((0, 0.5))  # r\n        \n    # Define the local minimization dictionary\n    cons = {'type': 'ineq', 'fun': constraints, 'jac': constraints_jac}\n    minimizer_kwargs = {\n        'method': 'SLSQP',\n        'jac': objective_grad,\n        'constraints': cons,\n        'bounds': bounds,\n        'options': {'maxiter': 100, 'ftol': 1e-6, 'disp': False}\n    }\n\n    # Custom step taking for Basin Hopping\n    class RandomDisplacement:\n        def __init__(self, stepsize=0.05):\n            self.stepsize = stepsize\n            \n        def __call__(self, x):\n            # Perturb x and y, keep r small or perturb slightly\n            # x structure: x, y, r, x, y, r...\n            s = self.stepsize\n            perturbation = np.random.uniform(-s, s, x.shape)\n            # Apply mainly to positions\n            mask = np.tile([1, 1, 0.1], N) # Less perturbation on radii\n            x_new = x + perturbation * mask\n            # Clip to bounds\n            x_new = np.clip(x_new, 0, 1)\n            # Ensure r is positive\n            x_new[2::3] = np.abs(x_new[2::3])\n            return x_new\n\n    # Run Basin Hopping\n    # T=0.002, niter=100 as requested\n    take_step = RandomDisplacement(stepsize=0.05)\n    \n    # First, run a quick optimization to get a valid start from the grid\n    res_start = minimize(objective, x0, jac=objective_grad, method='SLSQP', \n                         bounds=bounds, constraints=cons, options={'maxiter': 50})\n    x_start = res_start.x\n\n    # Run global optimization\n    res = basinhopping(objective, x_start, niter=100, T=0.002, \n                       minimizer_kwargs=minimizer_kwargs, take_step=take_step,\n                       seed=42)\n    \n    # Final refinement\n    res_final = minimize(objective, res.x, jac=objective_grad, method='SLSQP',\n                         bounds=bounds, constraints=cons, \n                         options={'maxiter': 500, 'ftol': 1e-9})\n    \n    p_opt = res_final.x\n    centers = np.vstack((p_opt[0::3], p_opt[1::3])).T\n    radii = p_opt[2::3]\n    total_r = np.sum(radii)\n    \n    return centers, radii, total_r\n\ndef run_packing():\n    return construct_packing()\n```",
  "reasoning": "",
  "timestamp": "2026-01-08T11:36:40.263052",
  "cost_data": null,
  "model_config": {
    "model": "gemini-3-pro-preview",
    "temperature": 0.7,
    "provider_debug": {
      "finish_reason": "STOP",
      "usage_metadata": {
        "prompt_token_count": 337,
        "candidates_token_count": 2446,
        "thoughts_token_count": 4607
      },
      "response_text_len": 6487
    }
  }
}