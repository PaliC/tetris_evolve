{
  "trial_id": "trial_7_1",
  "generation": 7,
  "parent_id": "trial_6_3",
  "code": "import numpy as np\nfrom scipy.optimize import minimize, linprog\n\ndef solve_radii_lp(centers):\n    \"\"\"Calculates maximal radii for fixed centers using Linear Programming.\"\"\"\n    n = len(centers)\n    # Objective: Maximize sum of radii\n    c_obj = -np.ones(n)\n    \n    # Boundary constraints: r_i <= x_i, r_i <= 1-x_i, etc.\n    # r_i <= min(xi, 1-xi, yi, 1-yi)\n    bounds_r = []\n    for i in range(n):\n        max_possible = np.min([centers[i, 0], 1.0 - centers[i, 0], centers[i, 1], 1.0 - centers[i, 1]])\n        bounds_r.append((0, max(0, max_possible)))\n    \n    # Pairwise distance constraints: r_i + r_j <= dist(c_i, c_j)\n    A_ub = []\n    b_ub = []\n    for i in range(n):\n        for j in range(i + 1, n):\n            row = np.zeros(n)\n            row[i] = 1\n            row[j] = 1\n            dist = np.linalg.norm(centers[i] - centers[j])\n            A_ub.append(row)\n            b_ub.append(dist)\n    \n    res = linprog(c_obj, A_ub=A_ub, b_ub=b_ub, bounds=bounds_r, method='highs')\n    if res.success:\n        return res.x\n    return np.zeros(n)\n\ndef construct_packing():\n    \"\"\"\n    Refined Topological Shake approach for n=26.\n    Combines Probabilistic Shaking, extended Lloyd relaxation, and SLSQP.\n    \"\"\"\n    n = 26\n    \n    # Initial Layout: 5x5 grid + 1\n    side = 5\n    x = np.linspace(0.1, 0.9, side)\n    y = np.linspace(0.1, 0.9, side)\n    xv, yv = np.meshgrid(x, y)\n    centers = np.stack([xv.flatten(), yv.flatten()], axis=1)\n    centers = np.vstack([centers, [0.5, 0.5]])[:n]\n    \n    def lloyd_step(c, iterations=30):\n        for _ in range(iterations):\n            for i in range(n):\n                diffs = c - c[i]\n                dists = np.linalg.norm(diffs, axis=1)\n                dists[i] = np.inf\n                nearest = np.argmin(dists)\n                if dists[nearest] < 0.15:\n                    # Move away from center of mass of neighbors\n                    force = diffs[nearest] / (dists[nearest]**2 + 1e-6)\n                    c[i] -= 0.02 * force\n            c = np.clip(c, 0.05, 0.95)\n        return c\n\n    def refine_slsqp(c_init, r_init):\n        def objective(params):\n            # Maximize sum of radii with a small log barrier to prevent r -> 0\n            r = params[2*n:]\n            return -np.sum(r) - 1e-4 * np.sum(np.log(r + 1e-7))\n\n        def constraints(params):\n            c = params[:2*n].reshape((n, 2))\n            r = params[2*n:]\n            cons = []\n            # Boundaries\n            for i in range(n):\n                cons.append(c[i, 0] - r[i])\n                cons.append(1.0 - c[i, 0] - r[i])\n                cons.append(c[i, 1] - r[i])\n                cons.append(1.0 - c[i, 1] - r[i])\n            # No overlap\n            for i in range(n):\n                for j in range(i + 1, n):\n                    dist_sq = np.sum((c[i] - c[j])**2)\n                    cons.append(dist_sq - (r[i] + r[j])**2)\n            return np.array(cons)\n\n        x0 = np.concatenate([c_init.flatten(), r_init])\n        res = minimize(objective, x0, method='SLSQP', \n                       constraints={'type': 'ineq', 'fun': constraints},\n                       options={'maxiter': 40, 'disp': False})\n        \n        if res.success:\n            return res.x[:2*n].reshape((n, 2)), res.x[2*n:]\n        return c_init, r_init\n\n    # Optimization Loop\n    best_c = centers\n    best_r = solve_radii_lp(centers)\n    best_sum = np.sum(best_r)\n    \n    curr_c, curr_r = np.copy(best_c), np.copy(best_r)\n    \n    for _ in range(60): # Iterations\n        # 1. Probabilistic Shake\n        temp_c = np.copy(curr_c)\n        prob = np.random.rand()\n        if prob < 0.7:\n            # Move 2 smallest\n            idx = np.argsort(curr_r)[:2]\n            temp_c[idx] = np.random.rand(2, 2) * 0.8 + 0.1\n        else:\n            # Swap large and small\n            idx_small = np.argmin(curr_r)\n            idx_large = np.argmax(curr_r)\n            temp_c[idx_small], temp_c[idx_large] = temp_c[idx_large].copy(), temp_c[idx_small].copy()\n            \n        # 2. Lloyd Relaxation\n        temp_c = lloyd_step(temp_c, 30)\n        temp_r = solve_radii_lp(temp_c)\n        \n        # 3. SLSQP Refinement\n        temp_c, temp_r = refine_slsqp(temp_c, temp_r)\n        temp_sum = np.sum(temp_r)\n        \n        # 4. Acceptance\n        if temp_sum > best_sum:\n            best_sum = temp_sum\n            best_c, best_r = np.copy(temp_c), np.copy(temp_r)\n            curr_c, curr_r = np.copy(temp_c), np.copy(temp_r)\n        elif temp_sum > best_sum * 0.9: # Basic basin hopping acceptance\n            curr_c, curr_r = np.copy(temp_c), np.copy(temp_r)\n\n    # Final feasibility enforcement\n    final_r = solve_radii_lp(best_c)\n    # Safety margin for floating point errors\n    final_r *= 0.9999999\n    \n    return best_c, final_r, np.sum(final_r)\n\ndef run_packing():\n    return construct_packing()",
  "metrics": {
    "valid": true,
    "score": 2.6290454041969773,
    "eval_time": 26.508699893951416,
    "error": null
  },
  "prompt": "Refine the 'Topological Shake' approach from trial_6_3 (score 2.6254).\n{{import numpy as np\nfrom scipy.optimize import minimize\n\ndef construct_packing():\n    \"\"\"\n    Pack 26 circles into a unit square to maximize the sum of radii.\n    Uses an iterative optimization approach combining Topological Shaking,\n    Lloyd iterations, and SLSQP refinement.\n    \"\"\"\n    n = 26\n    \n    # 1. Base Layout (Trial 1_2 style: Grid-like initialization with noise)\n    # We create a 5x5 grid + 1 extra circle\n    grid_size = int(np.ceil(np.sqrt(n)))\n    x = np.linspace(0.1, 0.9, grid_size)\n    y = np.linspace(0.1, 0.9, grid_size)\n    xv, yv = np.meshgrid(x, y)\n    centers = np.stack([xv.flatten(), yv.flatten()], axis=1)[:n]\n    \n    # If grid didn't provide enough, pad with random\n    if len(centers) < n:\n        pad = np.random.rand(n - len(centers), 2) * 0.8 + 0.1\n        centers = np.vstack([centers, pad])\n        \n    radii = np.full(n, 1.0 / (2 * grid_size))\n\n    def solve_radii(centers):\n        \"\"\"Calculates maximal radii for fixed centers under constraints.\"\"\"\n        n = len(centers)\n        # Distance to boundaries: r_i <= x_i, r_i <= 1-x_i, etc.\n        max_r = np.min(np.concatenate([centers, 1 - centers], axis=1), axis=1)\n        \n        # Pairwise distance constraint: r_i + r_j <= dist(c_i, c_j)\n        # We use a simplified model where we assign radii proportional to available space\n        # or solve a small LP. For speed in iterations, we use a heuristic:\n        # Each circle gets a radius, but they cannot overlap.\n        # This is the 'Equal Radii' sub-problem or 'Greedy' sub-problem.\n        # For the sum-of-radii objective, the optimal radii for fixed centers \n        # is a Linear Programming problem.\n        from scipy.optimize import linprog\n        c = -np.ones(n)\n        A_ub = []\n        b_ub = []\n        for i in range(n):\n            for j in range(i + 1, n):\n                row = np.zeros(n)\n                row[i] = 1\n                row[j] = 1\n                dist = np.linalg.norm(centers[i] - centers[j])\n                A_ub.append(row)\n                b_ub.append(dist)\n        \n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=[(0, None) for _ in range(n)], method='highs')\n        if res.success:\n            # Final check against boundaries\n            final_r = np.minimum(res.x, max_r)\n            return final_r\n        return np.zeros(n)\n\n    def lloyd_step(centers):\n        \"\"\"Simple Lloyd-like relaxation to space out centers.\"\"\"\n        new_centers = np.copy(centers)\n        for i in range(n):\n            # Move slightly away from nearest neighbors\n            diffs = centers - centers[i]\n            dists = np.linalg.norm(diffs, axis=1)\n            dists[i] = np.inf\n            nearest = np.argmin(dists)\n            if dists[nearest] < 0.1:\n                direction = diffs[nearest] / (dists[nearest] + 1e-9)\n                new_centers[i] -= direction * 0.01\n        return np.clip(new_centers, 0.01, 0.99)\n\n    def refine_slsqp(centers_init):\n        \"\"\"Local optimization of centers to maximize sum of radii.\"\"\"\n        n = len(centers_init)\n        \n        def objective(params):\n            # params: [x1, y1, ..., xn, yn, r1, ..., rn]\n            return -np.sum(params[2*n:])\n\n        def constraints(params):\n            c = params[:2*n].reshape((n, 2))\n            r = params[2*n:]\n            cons = []\n            # Boundary constraints\n            for i in range(n):\n                cons.append(c[i, 0] - r[i])\n                cons.append(1.0 - c[i, 0] - r[i])\n                cons.append(c[i, 1] - r[i])\n                cons.append(1.0 - c[i, 1] - r[i])\n            # Overlap constraints\n            for i in range(n):\n                for j in range(i + 1, n):\n                    dist = np.linalg.norm(c[i] - c[j])\n                    cons.append(dist - (r[i] + r[j]))\n            return np.array(cons)\n\n        # Initial r estimate\n        r_init = solve_radii(centers_init)\n        x0 = np.concatenate([centers_init.flatten(), r_init])\n        \n        res = minimize(objective, x0, method='SLSQP', \n                       constraints={'type': 'ineq', 'fun': constraints},\n                       options={'maxiter': 20, 'disp': False})\n        \n        if res.success:\n            refined_c = res.x[:2*n].reshape((n, 2))\n            refined_r = res.x[2*n:]\n            return refined_c, refined_r, -res.fun\n        return centers_init, r_init, np.sum(r_init)\n\n    # Main Meta-heuristic loop\n    best_centers = centers\n    best_radii = solve_radii(centers)\n    best_sum = np.sum(best_radii)\n    \n    current_centers = np.copy(best_centers)\n    current_sum = best_sum\n\n    for iteration in range(50):\n        # 1. Topological Shake: Move 2 smallest circles\n        temp_centers = np.copy(current_centers)\n        temp_radii = solve_radii(temp_centers)\n        idx_to_move = np.argsort(temp_radii)[:2]\n        temp_centers[idx_to_move] = np.random.rand(2, 2) * 0.8 + 0.1\n        \n        # 2. Lloyd Iterations\n        for _ in range(15):\n            temp_centers = lloyd_step(temp_centers)\n            \n        # 3. SLSQP Refinement\n        temp_centers, temp_radii, temp_sum = refine_slsqp(temp_centers)\n        \n        # 4. Metropolis Criterion\n        if temp_sum > current_sum or np.random.rand() < np.exp((temp_sum - current_sum) / 0.01):\n            current_centers = temp_centers\n            current_sum = temp_sum\n            \n            if current_sum > best_sum:\n                best_sum = current_sum\n                best_centers = np.copy(current_centers)\n                best_radii = np.copy(temp_radii)\n\n    # Final cleanup to ensure strict feasibility\n    final_centers = np.clip(best_centers, 0, 1)\n    # Re-solve radii with a small safety margin\n    final_radii = solve_radii(final_centers) * 0.999999 \n    \n    return final_centers, final_radii, np.sum(final_radii)\n\ndef run_packing():\n    \"\"\"Entry point called by evaluator.\"\"\"\n    return construct_packing()}}\n\n1. The current shake moves the 2 smallest circles. Modify this to a 'Probabilistic Shake':\n   - 70% chance: Move the 2 smallest circles to random locations.\n   - 30% chance: Randomly swap the positions of 2 circles (one large, one small).\n2. After each shake, apply 30 iterations of Lloyd's algorithm before the SLSQP step.\n3. Integrate the Logarithmic Barrier objective from trial_6_2 into the SLSQP step of the basin hopping loop to keep the 'shaken' circles from being immediately crushed.\n4. Run for 100 iterations of basin hopping if time permits.",
  "response": "```python\nimport numpy as np\nfrom scipy.optimize import minimize, linprog\n\ndef solve_radii_lp(centers):\n    \"\"\"Calculates maximal radii for fixed centers using Linear Programming.\"\"\"\n    n = len(centers)\n    # Objective: Maximize sum of radii\n    c_obj = -np.ones(n)\n    \n    # Boundary constraints: r_i <= x_i, r_i <= 1-x_i, etc.\n    # r_i <= min(xi, 1-xi, yi, 1-yi)\n    bounds_r = []\n    for i in range(n):\n        max_possible = np.min([centers[i, 0], 1.0 - centers[i, 0], centers[i, 1], 1.0 - centers[i, 1]])\n        bounds_r.append((0, max(0, max_possible)))\n    \n    # Pairwise distance constraints: r_i + r_j <= dist(c_i, c_j)\n    A_ub = []\n    b_ub = []\n    for i in range(n):\n        for j in range(i + 1, n):\n            row = np.zeros(n)\n            row[i] = 1\n            row[j] = 1\n            dist = np.linalg.norm(centers[i] - centers[j])\n            A_ub.append(row)\n            b_ub.append(dist)\n    \n    res = linprog(c_obj, A_ub=A_ub, b_ub=b_ub, bounds=bounds_r, method='highs')\n    if res.success:\n        return res.x\n    return np.zeros(n)\n\ndef construct_packing():\n    \"\"\"\n    Refined Topological Shake approach for n=26.\n    Combines Probabilistic Shaking, extended Lloyd relaxation, and SLSQP.\n    \"\"\"\n    n = 26\n    \n    # Initial Layout: 5x5 grid + 1\n    side = 5\n    x = np.linspace(0.1, 0.9, side)\n    y = np.linspace(0.1, 0.9, side)\n    xv, yv = np.meshgrid(x, y)\n    centers = np.stack([xv.flatten(), yv.flatten()], axis=1)\n    centers = np.vstack([centers, [0.5, 0.5]])[:n]\n    \n    def lloyd_step(c, iterations=30):\n        for _ in range(iterations):\n            for i in range(n):\n                diffs = c - c[i]\n                dists = np.linalg.norm(diffs, axis=1)\n                dists[i] = np.inf\n                nearest = np.argmin(dists)\n                if dists[nearest] < 0.15:\n                    # Move away from center of mass of neighbors\n                    force = diffs[nearest] / (dists[nearest]**2 + 1e-6)\n                    c[i] -= 0.02 * force\n            c = np.clip(c, 0.05, 0.95)\n        return c\n\n    def refine_slsqp(c_init, r_init):\n        def objective(params):\n            # Maximize sum of radii with a small log barrier to prevent r -> 0\n            r = params[2*n:]\n            return -np.sum(r) - 1e-4 * np.sum(np.log(r + 1e-7))\n\n        def constraints(params):\n            c = params[:2*n].reshape((n, 2))\n            r = params[2*n:]\n            cons = []\n            # Boundaries\n            for i in range(n):\n                cons.append(c[i, 0] - r[i])\n                cons.append(1.0 - c[i, 0] - r[i])\n                cons.append(c[i, 1] - r[i])\n                cons.append(1.0 - c[i, 1] - r[i])\n            # No overlap\n            for i in range(n):\n                for j in range(i + 1, n):\n                    dist_sq = np.sum((c[i] - c[j])**2)\n                    cons.append(dist_sq - (r[i] + r[j])**2)\n            return np.array(cons)\n\n        x0 = np.concatenate([c_init.flatten(), r_init])\n        res = minimize(objective, x0, method='SLSQP', \n                       constraints={'type': 'ineq', 'fun': constraints},\n                       options={'maxiter': 40, 'disp': False})\n        \n        if res.success:\n            return res.x[:2*n].reshape((n, 2)), res.x[2*n:]\n        return c_init, r_init\n\n    # Optimization Loop\n    best_c = centers\n    best_r = solve_radii_lp(centers)\n    best_sum = np.sum(best_r)\n    \n    curr_c, curr_r = np.copy(best_c), np.copy(best_r)\n    \n    for _ in range(60): # Iterations\n        # 1. Probabilistic Shake\n        temp_c = np.copy(curr_c)\n        prob = np.random.rand()\n        if prob < 0.7:\n            # Move 2 smallest\n            idx = np.argsort(curr_r)[:2]\n            temp_c[idx] = np.random.rand(2, 2) * 0.8 + 0.1\n        else:\n            # Swap large and small\n            idx_small = np.argmin(curr_r)\n            idx_large = np.argmax(curr_r)\n            temp_c[idx_small], temp_c[idx_large] = temp_c[idx_large].copy(), temp_c[idx_small].copy()\n            \n        # 2. Lloyd Relaxation\n        temp_c = lloyd_step(temp_c, 30)\n        temp_r = solve_radii_lp(temp_c)\n        \n        # 3. SLSQP Refinement\n        temp_c, temp_r = refine_slsqp(temp_c, temp_r)\n        temp_sum = np.sum(temp_r)\n        \n        # 4. Acceptance\n        if temp_sum > best_sum:\n            best_sum = temp_sum\n            best_c, best_r = np.copy(temp_c), np.copy(temp_r)\n            curr_c, curr_r = np.copy(temp_c), np.copy(temp_r)\n        elif temp_sum > best_sum * 0.9: # Basic basin hopping acceptance\n            curr_c, curr_r = np.copy(temp_c), np.copy(temp_r)\n\n    # Final feasibility enforcement\n    final_r = solve_radii_lp(best_c)\n    # Safety margin for floating point errors\n    final_r *= 0.9999999\n    \n    return best_c, final_r, np.sum(final_r)\n\ndef run_packing():\n    return construct_packing()\n```",
  "reasoning": "",
  "timestamp": "2025-12-24T22:26:00.467352",
  "cost_data": null
}