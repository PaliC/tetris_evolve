{
  "trial_id": "trial_1_4",
  "generation": 1,
  "parent_id": "trial_0_11",
  "code": "import numpy as np\n\ndef construct_packing():\n    \"\"\"\n    Construct a circle packing for n=26 circles in a unit square.\n\n    Returns:\n        centers: np.array of shape (26, 2) - (x, y) coordinates of circle centers\n        radii: np.array of shape (26,) - radius of each circle\n        sum_radii: float - sum of all radii\n    \"\"\"\n    n = 26\n    np.random.seed(42)\n    \n    # Initialize centers in a grid pattern with some randomness\n    grid_size = int(np.ceil(np.sqrt(n)))\n    centers = []\n    for i in range(grid_size):\n        for j in range(grid_size):\n            if len(centers) >= n:\n                break\n            x = (i + 0.5) / grid_size + np.random.randn() * 0.02\n            y = (j + 0.5) / grid_size + np.random.randn() * 0.02\n            centers.append([x, y])\n    centers = np.array(centers[:n])\n    \n    # Adam optimizer parameters\n    n_iterations = 25000\n    initial_lr = 0.02\n    beta1 = 0.9\n    beta2 = 0.999\n    epsilon_adam = 1e-8\n    lr_decay = 0.9998\n    \n    # Initialize Adam moments\n    m = np.zeros((n, 2))\n    v = np.zeros((n, 2))\n    \n    def compute_max_radii_binary_search(centers):\n        \"\"\"Compute maximum safe radius for each circle using binary search.\"\"\"\n        radii = np.zeros(n)\n        \n        for i in range(n):\n            # Distance to boundaries\n            min_dist_boundary = min(\n                centers[i, 0],\n                1.0 - centers[i, 0],\n                centers[i, 1],\n                1.0 - centers[i, 1]\n            )\n            \n            # Binary search for maximum radius\n            low, high = 0.0, min_dist_boundary\n            \n            for _ in range(30):  # Binary search iterations\n                mid = (low + high) / 2.0\n                \n                # Check if this radius is feasible (no overlap with other circles)\n                feasible = True\n                for j in range(n):\n                    if i != j:\n                        dist = np.linalg.norm(centers[i] - centers[j])\n                        # Need to estimate other circle's radius\n                        other_boundary = min(\n                            centers[j, 0],\n                            1.0 - centers[j, 0],\n                            centers[j, 1],\n                            1.0 - centers[j, 1]\n                        )\n                        # Conservative estimate: other circle could have radius up to distance/2\n                        min_separation = dist / 2.0\n                        if mid > min_separation:\n                            feasible = False\n                            break\n                \n                if feasible:\n                    low = mid\n                else:\n                    high = mid\n            \n            radii[i] = low\n        \n        return radii\n    \n    def compute_max_radii_iterative(centers, n_iter=5):\n        \"\"\"Iteratively compute radii considering actual neighbor radii.\"\"\"\n        radii = np.zeros(n)\n        \n        # Initial estimate\n        for i in range(n):\n            min_dist_boundary = min(\n                centers[i, 0],\n                1.0 - centers[i, 0],\n                centers[i, 1],\n                1.0 - centers[i, 1]\n            )\n            radii[i] = min_dist_boundary\n        \n        # Iteratively refine\n        for _ in range(n_iter):\n            new_radii = radii.copy()\n            for i in range(n):\n                # Distance to boundaries\n                min_dist_boundary = min(\n                    centers[i, 0],\n                    1.0 - centers[i, 0],\n                    centers[i, 1],\n                    1.0 - centers[i, 1]\n                )\n                \n                # Distance to other circles considering their radii\n                max_r = min_dist_boundary\n                for j in range(n):\n                    if i != j:\n                        dist = np.linalg.norm(centers[i] - centers[j])\n                        available = dist - radii[j]\n                        max_r = min(max_r, available)\n                \n                new_radii[i] = max(0, max_r)\n            \n            radii = new_radii\n        \n        return radii\n    \n    def objective(centers):\n        \"\"\"Compute sum of radii for given centers.\"\"\"\n        radii = compute_max_radii_iterative(centers)\n        return np.sum(radii), radii\n    \n    def numerical_gradient(centers, epsilon=1e-5):\n        \"\"\"Compute numerical gradient of objective w.r.t. centers.\"\"\"\n        grad = np.zeros_like(centers)\n        base_obj, _ = objective(centers)\n        \n        for i in range(n):\n            for j in range(2):  # x and y\n                centers_plus = centers.copy()\n                centers_plus[i, j] += epsilon\n                obj_plus, _ = objective(centers_plus)\n                \n                grad[i, j] = (obj_plus - base_obj) / epsilon\n        \n        return grad\n    \n    def line_search(centers, direction, base_obj, alpha_init=1.0, c=0.1, max_iter=10):\n        \"\"\"Backtracking line search to find optimal step size.\"\"\"\n        alpha = alpha_init\n        \n        for _ in range(max_iter):\n            new_centers = centers + alpha * direction\n            new_centers = project_to_feasible(new_centers)\n            new_obj, _ = objective(new_centers)\n            \n            # Armijo condition (sufficient decrease)\n            if new_obj >= base_obj + c * alpha * np.sum(direction * direction):\n                return alpha, new_centers, new_obj\n            \n            alpha *= 0.5\n        \n        return alpha, centers + alpha * direction, base_obj\n    \n    def project_to_feasible(centers, margin=0.005):\n        \"\"\"Project centers to ensure they stay within valid bounds.\"\"\"\n        centers = np.clip(centers, margin, 1.0 - margin)\n        return centers\n    \n    # Adam optimization with line search\n    best_centers = centers.copy()\n    best_sum = 0.0\n    \n    lr = initial_lr\n    t = 0\n    \n    for iteration in range(n_iterations):\n        t += 1\n        \n        # Compute gradient\n        grad = numerical_gradient(centers, epsilon=1e-5)\n        \n        # Adam update\n        m = beta1 * m + (1 - beta1) * grad\n        v = beta2 * v + (1 - beta2) * (grad ** 2)\n        \n        # Bias correction\n        m_hat = m / (1 - beta1 ** t)\n        v_hat = v / (1 - beta2 ** t)\n        \n        # Compute adaptive direction\n        direction = m_hat / (np.sqrt(v_hat) + epsilon_adam)\n        \n        # Line search for optimal step size\n        current_sum, _ = objective(centers)\n        alpha, new_centers, new_sum = line_search(\n            centers, lr * direction, current_sum, alpha_init=1.0\n        )\n        \n        centers = new_centers\n        \n        # Keep track of best solution\n        if new_sum > best_sum:\n            best_sum = new_sum\n            best_centers = centers.copy()\n        \n        # Learning rate decay\n        lr *= lr_decay\n        \n        # Adaptive restart with momentum reset\n        if iteration > 0 and iteration % 1000 == 0:\n            if new_sum < best_sum * 0.98:\n                # Reset to best with perturbation\n                centers = best_centers.copy()\n                centers += np.random.randn(n, 2) * 0.008\n                centers = project_to_feasible(centers)\n                # Reset momentum\n                m = np.zeros((n, 2))\n                v = np.zeros((n, 2))\n                t = 0\n                lr = initial_lr * 0.7\n    \n    # Multi-start refinement with best configuration\n    for restart in range(3):\n        # Local refinement around best solution\n        test_centers = best_centers.copy()\n        test_centers += np.random.randn(n, 2) * 0.003 * (1.0 / (restart + 1))\n        test_centers = project_to_feasible(test_centers)\n        \n        # Short optimization run\n        local_m = np.zeros((n, 2))\n        local_v = np.zeros((n, 2))\n        local_lr = initial_lr * 0.3\n        local_t = 0\n        \n        for local_iter in range(2000):\n            local_t += 1\n            grad = numerical_gradient(test_centers, epsilon=1e-5)\n            \n            local_m = beta1 * local_m + (1 - beta1) * grad\n            local_v = beta2 * local_v + (1 - beta2) * (grad ** 2)\n            \n            m_hat = local_m / (1 - beta1 ** local_t)\n            v_hat = local_v / (1 - beta2 ** local_t)\n            \n            direction = m_hat / (np.sqrt(v_hat) + epsilon_adam)\n            \n            test_centers = test_centers + local_lr * direction\n            test_centers = project_to_feasible(test_centers)\n            \n            local_lr *= 0.999\n        \n        test_radii = compute_max_radii_iterative(test_centers)\n        test_sum = np.sum(test_radii)\n        \n        if test_sum > best_sum:\n            best_sum = test_sum\n            best_centers = test_centers.copy()\n    \n    # Final evaluation with best centers\n    final_radii = compute_max_radii_iterative(best_centers, n_iter=10)\n    final_sum = np.sum(final_radii)\n    \n    return best_centers, final_radii, final_sum\n\ndef run_packing():\n    \"\"\"Entry point called by evaluator.\"\"\"\n    return construct_packing()",
  "metrics": {
    "valid": false,
    "sum_radii": 0.0,
    "target_ratio": 0.0,
    "combined_score": 0.0,
    "eval_time": 300.0071222782135,
    "error": "Timeout after 300s"
  },
  "prompt": "Improve this gradient descent circle packing:\n\nimport numpy as np\n\ndef construct_packing():\n    \"\"\"\n    Construct a circle packing for n=26 circles in a unit square.\n\n    Returns:\n        centers: np.array of shape (26, 2) - (x, y) coordinates of circle centers\n        radii: np.array of shape (26,) - radius of each circle\n        sum_radii: float - sum of all radii\n    \"\"\"\n    n = 26\n    np.random.seed(42)\n    \n    # Initialize centers in a grid pattern with some randomness\n    grid_size = int(np.ceil(np.sqrt(n)))\n    centers = []\n    for i in range(grid_size):\n        for j in range(grid_size):\n            if len(centers) >= n:\n                break\n            x = (i + 0.5) / grid_size + np.random.randn() * 0.02\n            y = (j + 0.5) / grid_size + np.random.randn() * 0.02\n            centers.append([x, y])\n    centers = np.array(centers[:n])\n    \n    # Optimization parameters\n    n_iterations = 5000\n    initial_lr = 0.01\n    lr_decay = 0.9995\n    epsilon = 1e-6\n    \n    def compute_max_radii(centers):\n        \"\"\"Compute maximum safe radius for each circle given center positions.\"\"\"\n        radii = np.zeros(n)\n        \n        for i in range(n):\n            # Distance to boundaries\n            min_dist_boundary = min(\n                centers[i, 0],\n                1.0 - centers[i, 0],\n                centers[i, 1],\n                1.0 - centers[i, 1]\n            )\n            \n            # Distance to other circles\n            min_dist_circles = np.inf\n            for j in range(n):\n                if i != j:\n                    dist = np.linalg.norm(centers[i] - centers[j])\n                    min_dist_circles = min(min_dist_circles, dist)\n            \n            # Maximum radius is half the minimum distance to other circles\n            # (since other circles can have the same radius)\n            max_r = min(min_dist_boundary, min_dist_circles / 2.0)\n            radii[i] = max(0, max_r)\n        \n        return radii\n    \n    def objective(centers):\n        \"\"\"Compute sum of radii for given centers.\"\"\"\n        radii = compute_max_radii(centers)\n        return np.sum(radii), radii\n    \n    def numerical_gradient(centers, epsilon=1e-5):\n        \"\"\"Compute numerical gradient of objective w.r.t. centers.\"\"\"\n        grad = np.zeros_like(centers)\n        base_obj, _ = objective(centers)\n        \n        for i in range(n):\n            for j in range(2):  # x and y\n                centers_plus = centers.copy()\n                centers_plus[i, j] += epsilon\n                obj_plus, _ = objective(centers_plus)\n                \n                grad[i, j] = (obj_plus - base_obj) / epsilon\n        \n        return grad\n    \n    def project_to_feasible(centers, margin=0.01):\n        \"\"\"Project centers to ensure they stay within valid bounds.\"\"\"\n        centers = np.clip(centers, margin, 1.0 - margin)\n        return centers\n    \n    # Gradient ascent optimization\n    best_centers = centers.copy()\n    best_sum = 0.0\n    \n    lr = initial_lr\n    \n    for iteration in range(n_iterations):\n        # Compute gradient\n        grad = numerical_gradient(centers, epsilon=epsilon)\n        \n        # Update centers with gradient ascent\n        centers = centers + lr * grad\n        \n        # Project back to feasible region\n        centers = project_to_feasible(centers)\n        \n        # Evaluate current solution\n        current_sum, current_radii = objective(centers)\n        \n        # Keep track of best solution\n        if current_sum > best_sum:\n            best_sum = current_sum\n            best_centers = centers.copy()\n        \n        # Learning rate decay\n        lr *= lr_decay\n        \n        # Adaptive restart if stuck\n        if iteration > 0 and iteration % 500 == 0:\n            if current_sum < best_sum * 0.95:\n                # Add small perturbation to escape local minimum\n                centers = best_centers.copy()\n                centers += np.random.randn(n, 2) * 0.01\n                centers = project_to_feasible(centers)\n                lr = initial_lr * 0.5\n    \n    # Final evaluation with best centers\n    final_radii = compute_max_radii(best_centers)\n    final_sum = np.sum(final_radii)\n    \n    # Additional refinement: try to balance radii more evenly\n    for refinement in range(1000):\n        # Find circle with smallest radius\n        min_idx = np.argmin(final_radii)\n        \n        # Try small random moves\n        best_local = best_centers.copy()\n        best_local_sum = final_sum\n        \n        for _ in range(10):\n            test_centers = best_centers.copy()\n            test_centers[min_idx] += np.random.randn(2) * 0.005\n            test_centers = project_to_feasible(test_centers)\n            \n            test_radii = compute_max_radii(test_centers)\n            test_sum = np.sum(test_radii)\n            \n            if test_sum > best_local_sum:\n                best_local = test_centers.copy()\n                best_local_sum = test_sum\n        \n        if best_local_sum > final_sum:\n            best_centers = best_local.copy()\n            final_sum = best_local_sum\n            final_radii = compute_max_radii(best_centers)\n        else:\n            break\n    \n    return best_centers, final_radii, final_sum\n\ndef run_packing():\n    \"\"\"Entry point called by evaluator.\"\"\"\n    return construct_packing()\n\nImprovements:\n1. Implement momentum-based gradient descent (add velocity terms)\n2. Use adaptive learning rates per circle (AdaGrad or Adam-style)\n3. Add line search to find optimal step size\n4. Increase iterations to 20000+\n5. Better radius computation: for each position, binary search for maximum safe radius\n\nRequirements:\n- Keep gradient-based approach\n- Add modern optimization techniques\n- No plotting or printing",
  "response": "```python\nimport numpy as np\n\ndef construct_packing():\n    \"\"\"\n    Construct a circle packing for n=26 circles in a unit square.\n\n    Returns:\n        centers: np.array of shape (26, 2) - (x, y) coordinates of circle centers\n        radii: np.array of shape (26,) - radius of each circle\n        sum_radii: float - sum of all radii\n    \"\"\"\n    n = 26\n    np.random.seed(42)\n    \n    # Initialize centers in a grid pattern with some randomness\n    grid_size = int(np.ceil(np.sqrt(n)))\n    centers = []\n    for i in range(grid_size):\n        for j in range(grid_size):\n            if len(centers) >= n:\n                break\n            x = (i + 0.5) / grid_size + np.random.randn() * 0.02\n            y = (j + 0.5) / grid_size + np.random.randn() * 0.02\n            centers.append([x, y])\n    centers = np.array(centers[:n])\n    \n    # Adam optimizer parameters\n    n_iterations = 25000\n    initial_lr = 0.02\n    beta1 = 0.9\n    beta2 = 0.999\n    epsilon_adam = 1e-8\n    lr_decay = 0.9998\n    \n    # Initialize Adam moments\n    m = np.zeros((n, 2))\n    v = np.zeros((n, 2))\n    \n    def compute_max_radii_binary_search(centers):\n        \"\"\"Compute maximum safe radius for each circle using binary search.\"\"\"\n        radii = np.zeros(n)\n        \n        for i in range(n):\n            # Distance to boundaries\n            min_dist_boundary = min(\n                centers[i, 0],\n                1.0 - centers[i, 0],\n                centers[i, 1],\n                1.0 - centers[i, 1]\n            )\n            \n            # Binary search for maximum radius\n            low, high = 0.0, min_dist_boundary\n            \n            for _ in range(30):  # Binary search iterations\n                mid = (low + high) / 2.0\n                \n                # Check if this radius is feasible (no overlap with other circles)\n                feasible = True\n                for j in range(n):\n                    if i != j:\n                        dist = np.linalg.norm(centers[i] - centers[j])\n                        # Need to estimate other circle's radius\n                        other_boundary = min(\n                            centers[j, 0],\n                            1.0 - centers[j, 0],\n                            centers[j, 1],\n                            1.0 - centers[j, 1]\n                        )\n                        # Conservative estimate: other circle could have radius up to distance/2\n                        min_separation = dist / 2.0\n                        if mid > min_separation:\n                            feasible = False\n                            break\n                \n                if feasible:\n                    low = mid\n                else:\n                    high = mid\n            \n            radii[i] = low\n        \n        return radii\n    \n    def compute_max_radii_iterative(centers, n_iter=5):\n        \"\"\"Iteratively compute radii considering actual neighbor radii.\"\"\"\n        radii = np.zeros(n)\n        \n        # Initial estimate\n        for i in range(n):\n            min_dist_boundary = min(\n                centers[i, 0],\n                1.0 - centers[i, 0],\n                centers[i, 1],\n                1.0 - centers[i, 1]\n            )\n            radii[i] = min_dist_boundary\n        \n        # Iteratively refine\n        for _ in range(n_iter):\n            new_radii = radii.copy()\n            for i in range(n):\n                # Distance to boundaries\n                min_dist_boundary = min(\n                    centers[i, 0],\n                    1.0 - centers[i, 0],\n                    centers[i, 1],\n                    1.0 - centers[i, 1]\n                )\n                \n                # Distance to other circles considering their radii\n                max_r = min_dist_boundary\n                for j in range(n):\n                    if i != j:\n                        dist = np.linalg.norm(centers[i] - centers[j])\n                        available = dist - radii[j]\n                        max_r = min(max_r, available)\n                \n                new_radii[i] = max(0, max_r)\n            \n            radii = new_radii\n        \n        return radii\n    \n    def objective(centers):\n        \"\"\"Compute sum of radii for given centers.\"\"\"\n        radii = compute_max_radii_iterative(centers)\n        return np.sum(radii), radii\n    \n    def numerical_gradient(centers, epsilon=1e-5):\n        \"\"\"Compute numerical gradient of objective w.r.t. centers.\"\"\"\n        grad = np.zeros_like(centers)\n        base_obj, _ = objective(centers)\n        \n        for i in range(n):\n            for j in range(2):  # x and y\n                centers_plus = centers.copy()\n                centers_plus[i, j] += epsilon\n                obj_plus, _ = objective(centers_plus)\n                \n                grad[i, j] = (obj_plus - base_obj) / epsilon\n        \n        return grad\n    \n    def line_search(centers, direction, base_obj, alpha_init=1.0, c=0.1, max_iter=10):\n        \"\"\"Backtracking line search to find optimal step size.\"\"\"\n        alpha = alpha_init\n        \n        for _ in range(max_iter):\n            new_centers = centers + alpha * direction\n            new_centers = project_to_feasible(new_centers)\n            new_obj, _ = objective(new_centers)\n            \n            # Armijo condition (sufficient decrease)\n            if new_obj >= base_obj + c * alpha * np.sum(direction * direction):\n                return alpha, new_centers, new_obj\n            \n            alpha *= 0.5\n        \n        return alpha, centers + alpha * direction, base_obj\n    \n    def project_to_feasible(centers, margin=0.005):\n        \"\"\"Project centers to ensure they stay within valid bounds.\"\"\"\n        centers = np.clip(centers, margin, 1.0 - margin)\n        return centers\n    \n    # Adam optimization with line search\n    best_centers = centers.copy()\n    best_sum = 0.0\n    \n    lr = initial_lr\n    t = 0\n    \n    for iteration in range(n_iterations):\n        t += 1\n        \n        # Compute gradient\n        grad = numerical_gradient(centers, epsilon=1e-5)\n        \n        # Adam update\n        m = beta1 * m + (1 - beta1) * grad\n        v = beta2 * v + (1 - beta2) * (grad ** 2)\n        \n        # Bias correction\n        m_hat = m / (1 - beta1 ** t)\n        v_hat = v / (1 - beta2 ** t)\n        \n        # Compute adaptive direction\n        direction = m_hat / (np.sqrt(v_hat) + epsilon_adam)\n        \n        # Line search for optimal step size\n        current_sum, _ = objective(centers)\n        alpha, new_centers, new_sum = line_search(\n            centers, lr * direction, current_sum, alpha_init=1.0\n        )\n        \n        centers = new_centers\n        \n        # Keep track of best solution\n        if new_sum > best_sum:\n            best_sum = new_sum\n            best_centers = centers.copy()\n        \n        # Learning rate decay\n        lr *= lr_decay\n        \n        # Adaptive restart with momentum reset\n        if iteration > 0 and iteration % 1000 == 0:\n            if new_sum < best_sum * 0.98:\n                # Reset to best with perturbation\n                centers = best_centers.copy()\n                centers += np.random.randn(n, 2) * 0.008\n                centers = project_to_feasible(centers)\n                # Reset momentum\n                m = np.zeros((n, 2))\n                v = np.zeros((n, 2))\n                t = 0\n                lr = initial_lr * 0.7\n    \n    # Multi-start refinement with best configuration\n    for restart in range(3):\n        # Local refinement around best solution\n        test_centers = best_centers.copy()\n        test_centers += np.random.randn(n, 2) * 0.003 * (1.0 / (restart + 1))\n        test_centers = project_to_feasible(test_centers)\n        \n        # Short optimization run\n        local_m = np.zeros((n, 2))\n        local_v = np.zeros((n, 2))\n        local_lr = initial_lr * 0.3\n        local_t = 0\n        \n        for local_iter in range(2000):\n            local_t += 1\n            grad = numerical_gradient(test_centers, epsilon=1e-5)\n            \n            local_m = beta1 * local_m + (1 - beta1) * grad\n            local_v = beta2 * local_v + (1 - beta2) * (grad ** 2)\n            \n            m_hat = local_m / (1 - beta1 ** local_t)\n            v_hat = local_v / (1 - beta2 ** local_t)\n            \n            direction = m_hat / (np.sqrt(v_hat) + epsilon_adam)\n            \n            test_centers = test_centers + local_lr * direction\n            test_centers = project_to_feasible(test_centers)\n            \n            local_lr *= 0.999\n        \n        test_radii = compute_max_radii_iterative(test_centers)\n        test_sum = np.sum(test_radii)\n        \n        if test_sum > best_sum:\n            best_sum = test_sum\n            best_centers = test_centers.copy()\n    \n    # Final evaluation with best centers\n    final_radii = compute_max_radii_iterative(best_centers, n_iter=10)\n    final_sum = np.sum(final_radii)\n    \n    return best_centers, final_radii, final_sum\n\ndef run_packing():\n    \"\"\"Entry point called by evaluator.\"\"\"\n    return construct_packing()\n```",
  "reasoning": "",
  "timestamp": "2025-12-16T17:58:02.222058",
  "cost_data": null
}