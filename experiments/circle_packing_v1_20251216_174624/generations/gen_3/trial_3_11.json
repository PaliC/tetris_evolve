{
  "trial_id": "trial_3_11",
  "generation": 3,
  "parent_id": null,
  "code": "import numpy as np\nfrom scipy.optimize import minimize\nfrom typing import Tuple\n\ndef construct_packing():\n    \"\"\"\n    Construct a circle packing for n=26 circles in a unit square using augmented Lagrangian method.\n\n    Returns:\n        centers: np.array of shape (26, 2) - (x, y) coordinates of circle centers\n        radii: np.array of shape (26,) - radius of each circle\n        sum_radii: float - sum of all radii\n    \"\"\"\n    n = 26\n    \n    # Initialize with a grid-based layout\n    grid_size = int(np.ceil(np.sqrt(n)))\n    initial_centers = []\n    spacing = 1.0 / (grid_size + 1)\n    \n    for i in range(n):\n        row = i // grid_size\n        col = i % grid_size\n        x = (col + 1) * spacing + 0.1 * (np.random.rand() - 0.5)\n        y = (row + 1) * spacing + 0.1 * (np.random.rand() - 0.5)\n        initial_centers.append([x, y])\n    \n    initial_centers = np.array(initial_centers)\n    initial_radii = np.ones(n) * 0.05\n    \n    # Pack variables: [centers (2*n), radii (n)]\n    x0 = np.concatenate([initial_centers.flatten(), initial_radii])\n    \n    # Augmented Lagrangian parameters\n    lambda_ineq = []  # Lagrange multipliers for inequality constraints\n    mu = 1.0  # Penalty parameter\n    mu_max = 1e6\n    mu_factor = 2.0\n    \n    # Initialize multipliers for all constraints\n    # Boundary constraints: 4*n (left, right, bottom, top for each circle)\n    # Non-overlap constraints: n*(n-1)/2\n    n_boundary = 4 * n\n    n_overlap = n * (n - 1) // 2\n    n_constraints = n_boundary + n_overlap\n    lambda_ineq = np.zeros(n_constraints)\n    \n    def unpack_variables(x):\n        centers = x[:2*n].reshape(n, 2)\n        radii = x[2*n:]\n        return centers, radii\n    \n    def compute_constraints(x):\n        \"\"\"Compute all inequality constraints (should be >= 0)\"\"\"\n        centers, radii = unpack_variables(x)\n        constraints = []\n        \n        # Boundary constraints: center - radius >= 0 and center + radius <= 1\n        for i in range(n):\n            constraints.append(centers[i, 0] - radii[i])  # left\n            constraints.append(1.0 - centers[i, 0] - radii[i])  # right\n            constraints.append(centers[i, 1] - radii[i])  # bottom\n            constraints.append(1.0 - centers[i, 1] - radii[i])  # top\n        \n        # Non-overlap constraints: distance - sum of radii >= 0\n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.linalg.norm(centers[i] - centers[j])\n                constraints.append(dist - radii[i] - radii[j])\n        \n        return np.array(constraints)\n    \n    def augmented_lagrangian(x, lambda_vec, mu):\n        \"\"\"Augmented Lagrangian objective function\"\"\"\n        centers, radii = unpack_variables(x)\n        \n        # Original objective: maximize sum of radii (minimize negative sum)\n        obj = -np.sum(radii)\n        \n        # Compute constraints\n        g = compute_constraints(x)\n        \n        # Augmented Lagrangian terms\n        for i, gi in enumerate(g):\n            if lambda_vec[i] - mu * gi > 0:\n                obj += lambda_vec[i] * gi + 0.5 * mu * gi**2\n            else:\n                obj -= 0.5 * lambda_vec[i]**2 / mu\n        \n        return obj\n    \n    def augmented_lagrangian_grad(x, lambda_vec, mu):\n        \"\"\"Gradient of augmented Lagrangian\"\"\"\n        centers, radii = unpack_variables(x)\n        grad = np.zeros_like(x)\n        \n        # Gradient of original objective\n        grad[2*n:] = -1.0  # derivative w.r.t. radii\n        \n        # Compute constraints and their gradients\n        g = compute_constraints(x)\n        \n        constraint_idx = 0\n        \n        # Boundary constraint gradients\n        for i in range(n):\n            # Left boundary: centers[i,0] - radii[i] >= 0\n            gi = g[constraint_idx]\n            if lambda_vec[constraint_idx] - mu * gi > 0:\n                coeff = lambda_vec[constraint_idx] + mu * gi\n                grad[2*i] += coeff  # d/d(centers[i,0])\n                grad[2*n + i] -= coeff  # d/d(radii[i])\n            constraint_idx += 1\n            \n            # Right boundary: 1 - centers[i,0] - radii[i] >= 0\n            gi = g[constraint_idx]\n            if lambda_vec[constraint_idx] - mu * gi > 0:\n                coeff = lambda_vec[constraint_idx] + mu * gi\n                grad[2*i] -= coeff\n                grad[2*n + i] -= coeff\n            constraint_idx += 1\n            \n            # Bottom boundary: centers[i,1] - radii[i] >= 0\n            gi = g[constraint_idx]\n            if lambda_vec[constraint_idx] - mu * gi > 0:\n                coeff = lambda_vec[constraint_idx] + mu * gi\n                grad[2*i + 1] += coeff  # d/d(centers[i,1])\n                grad[2*n + i] -= coeff\n            constraint_idx += 1\n            \n            # Top boundary: 1 - centers[i,1] - radii[i] >= 0\n            gi = g[constraint_idx]\n            if lambda_vec[constraint_idx] - mu * gi > 0:\n                coeff = lambda_vec[constraint_idx] + mu * gi\n                grad[2*i + 1] -= coeff\n                grad[2*n + i] -= coeff\n            constraint_idx += 1\n        \n        # Non-overlap constraint gradients\n        for i in range(n):\n            for j in range(i + 1, n):\n                gi = g[constraint_idx]\n                if lambda_vec[constraint_idx] - mu * gi > 0:\n                    coeff = lambda_vec[constraint_idx] + mu * gi\n                    dist = np.linalg.norm(centers[i] - centers[j])\n                    if dist > 1e-10:\n                        direction = (centers[i] - centers[j]) / dist\n                        grad[2*i:2*i+2] += coeff * direction\n                        grad[2*j:2*j+2] -= coeff * direction\n                    grad[2*n + i] -= coeff\n                    grad[2*n + j] -= coeff\n                constraint_idx += 1\n        \n        return grad\n    \n    # Augmented Lagrangian iterations\n    x_current = x0.copy()\n    max_outer_iter = 20\n    \n    for outer_iter in range(max_outer_iter):\n        # Optimize augmented Lagrangian\n        result = minimize(\n            fun=lambda x: augmented_lagrangian(x, lambda_ineq, mu),\n            x0=x_current,\n            jac=lambda x: augmented_lagrangian_grad(x, lambda_ineq, mu),\n            method='L-BFGS-B',\n            bounds=[(0, 1)]*(2*n) + [(0, 0.5)]*n,\n            options={'maxiter': 500, 'ftol': 1e-9}\n        )\n        \n        x_current = result.x\n        \n        # Update Lagrange multipliers\n        g = compute_constraints(x_current)\n        for i in range(len(lambda_ineq)):\n            lambda_ineq[i] = max(0, lambda_ineq[i] + mu * g[i])\n        \n        # Check convergence\n        constraint_violation = np.maximum(0, -g).sum()\n        if constraint_violation < 1e-6:\n            break\n        \n        # Increase penalty parameter\n        if mu < mu_max:\n            mu = min(mu * mu_factor, mu_max)\n    \n    # Final refinement with direct constraint optimization\n    def objective(x):\n        _, radii = unpack_variables(x)\n        return -np.sum(radii)\n    \n    def constraint_funcs(x):\n        return compute_constraints(x)\n    \n    constraints = {'type': 'ineq', 'fun': constraint_funcs}\n    \n    result_final = minimize(\n        fun=objective,\n        x0=x_current,\n        method='SLSQP',\n        bounds=[(0, 1)]*(2*n) + [(0, 0.5)]*n,\n        constraints=constraints,\n        options={'maxiter': 1000, 'ftol': 1e-10}\n    )\n    \n    centers, radii = unpack_variables(result_final.x)\n    sum_radii = np.sum(radii)\n    \n    return centers, radii, sum_radii\n\ndef run_packing():\n    \"\"\"Entry point called by evaluator.\"\"\"\n    return construct_packing()",
  "metrics": {
    "valid": true,
    "sum_radii": 2.5987582562998655,
    "target_ratio": 0.9862460175711065,
    "combined_score": 0.9862460175711065,
    "eval_time": 1.9439170360565186,
    "error": null
  },
  "prompt": "Create augmented Lagrangian optimizer for circle packing.\n\nStrategy:\n1. Formulate with Lagrange multipliers for constraints\n2. Iteratively:\n   - Optimize augmented Lagrangian (unconstrained)\n   - Update multipliers\n   - Increase penalty parameter\n3. This handles constraints more robustly\n4. Run until convergence\n5. Final refinement pass\n\nRequirements:\n- Augmented Lagrangian implementation\n- Iterative multiplier updates\n- No plotting or printing",
  "response": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom typing import Tuple\n\ndef construct_packing():\n    \"\"\"\n    Construct a circle packing for n=26 circles in a unit square using augmented Lagrangian method.\n\n    Returns:\n        centers: np.array of shape (26, 2) - (x, y) coordinates of circle centers\n        radii: np.array of shape (26,) - radius of each circle\n        sum_radii: float - sum of all radii\n    \"\"\"\n    n = 26\n    \n    # Initialize with a grid-based layout\n    grid_size = int(np.ceil(np.sqrt(n)))\n    initial_centers = []\n    spacing = 1.0 / (grid_size + 1)\n    \n    for i in range(n):\n        row = i // grid_size\n        col = i % grid_size\n        x = (col + 1) * spacing + 0.1 * (np.random.rand() - 0.5)\n        y = (row + 1) * spacing + 0.1 * (np.random.rand() - 0.5)\n        initial_centers.append([x, y])\n    \n    initial_centers = np.array(initial_centers)\n    initial_radii = np.ones(n) * 0.05\n    \n    # Pack variables: [centers (2*n), radii (n)]\n    x0 = np.concatenate([initial_centers.flatten(), initial_radii])\n    \n    # Augmented Lagrangian parameters\n    lambda_ineq = []  # Lagrange multipliers for inequality constraints\n    mu = 1.0  # Penalty parameter\n    mu_max = 1e6\n    mu_factor = 2.0\n    \n    # Initialize multipliers for all constraints\n    # Boundary constraints: 4*n (left, right, bottom, top for each circle)\n    # Non-overlap constraints: n*(n-1)/2\n    n_boundary = 4 * n\n    n_overlap = n * (n - 1) // 2\n    n_constraints = n_boundary + n_overlap\n    lambda_ineq = np.zeros(n_constraints)\n    \n    def unpack_variables(x):\n        centers = x[:2*n].reshape(n, 2)\n        radii = x[2*n:]\n        return centers, radii\n    \n    def compute_constraints(x):\n        \"\"\"Compute all inequality constraints (should be >= 0)\"\"\"\n        centers, radii = unpack_variables(x)\n        constraints = []\n        \n        # Boundary constraints: center - radius >= 0 and center + radius <= 1\n        for i in range(n):\n            constraints.append(centers[i, 0] - radii[i])  # left\n            constraints.append(1.0 - centers[i, 0] - radii[i])  # right\n            constraints.append(centers[i, 1] - radii[i])  # bottom\n            constraints.append(1.0 - centers[i, 1] - radii[i])  # top\n        \n        # Non-overlap constraints: distance - sum of radii >= 0\n        for i in range(n):\n            for j in range(i + 1, n):\n                dist = np.linalg.norm(centers[i] - centers[j])\n                constraints.append(dist - radii[i] - radii[j])\n        \n        return np.array(constraints)\n    \n    def augmented_lagrangian(x, lambda_vec, mu):\n        \"\"\"Augmented Lagrangian objective function\"\"\"\n        centers, radii = unpack_variables(x)\n        \n        # Original objective: maximize sum of radii (minimize negative sum)\n        obj = -np.sum(radii)\n        \n        # Compute constraints\n        g = compute_constraints(x)\n        \n        # Augmented Lagrangian terms\n        for i, gi in enumerate(g):\n            if lambda_vec[i] - mu * gi > 0:\n                obj += lambda_vec[i] * gi + 0.5 * mu * gi**2\n            else:\n                obj -= 0.5 * lambda_vec[i]**2 / mu\n        \n        return obj\n    \n    def augmented_lagrangian_grad(x, lambda_vec, mu):\n        \"\"\"Gradient of augmented Lagrangian\"\"\"\n        centers, radii = unpack_variables(x)\n        grad = np.zeros_like(x)\n        \n        # Gradient of original objective\n        grad[2*n:] = -1.0  # derivative w.r.t. radii\n        \n        # Compute constraints and their gradients\n        g = compute_constraints(x)\n        \n        constraint_idx = 0\n        \n        # Boundary constraint gradients\n        for i in range(n):\n            # Left boundary: centers[i,0] - radii[i] >= 0\n            gi = g[constraint_idx]\n            if lambda_vec[constraint_idx] - mu * gi > 0:\n                coeff = lambda_vec[constraint_idx] + mu * gi\n                grad[2*i] += coeff  # d/d(centers[i,0])\n                grad[2*n + i] -= coeff  # d/d(radii[i])\n            constraint_idx += 1\n            \n            # Right boundary: 1 - centers[i,0] - radii[i] >= 0\n            gi = g[constraint_idx]\n            if lambda_vec[constraint_idx] - mu * gi > 0:\n                coeff = lambda_vec[constraint_idx] + mu * gi\n                grad[2*i] -= coeff\n                grad[2*n + i] -= coeff\n            constraint_idx += 1\n            \n            # Bottom boundary: centers[i,1] - radii[i] >= 0\n            gi = g[constraint_idx]\n            if lambda_vec[constraint_idx] - mu * gi > 0:\n                coeff = lambda_vec[constraint_idx] + mu * gi\n                grad[2*i + 1] += coeff  # d/d(centers[i,1])\n                grad[2*n + i] -= coeff\n            constraint_idx += 1\n            \n            # Top boundary: 1 - centers[i,1] - radii[i] >= 0\n            gi = g[constraint_idx]\n            if lambda_vec[constraint_idx] - mu * gi > 0:\n                coeff = lambda_vec[constraint_idx] + mu * gi\n                grad[2*i + 1] -= coeff\n                grad[2*n + i] -= coeff\n            constraint_idx += 1\n        \n        # Non-overlap constraint gradients\n        for i in range(n):\n            for j in range(i + 1, n):\n                gi = g[constraint_idx]\n                if lambda_vec[constraint_idx] - mu * gi > 0:\n                    coeff = lambda_vec[constraint_idx] + mu * gi\n                    dist = np.linalg.norm(centers[i] - centers[j])\n                    if dist > 1e-10:\n                        direction = (centers[i] - centers[j]) / dist\n                        grad[2*i:2*i+2] += coeff * direction\n                        grad[2*j:2*j+2] -= coeff * direction\n                    grad[2*n + i] -= coeff\n                    grad[2*n + j] -= coeff\n                constraint_idx += 1\n        \n        return grad\n    \n    # Augmented Lagrangian iterations\n    x_current = x0.copy()\n    max_outer_iter = 20\n    \n    for outer_iter in range(max_outer_iter):\n        # Optimize augmented Lagrangian\n        result = minimize(\n            fun=lambda x: augmented_lagrangian(x, lambda_ineq, mu),\n            x0=x_current,\n            jac=lambda x: augmented_lagrangian_grad(x, lambda_ineq, mu),\n            method='L-BFGS-B',\n            bounds=[(0, 1)]*(2*n) + [(0, 0.5)]*n,\n            options={'maxiter': 500, 'ftol': 1e-9}\n        )\n        \n        x_current = result.x\n        \n        # Update Lagrange multipliers\n        g = compute_constraints(x_current)\n        for i in range(len(lambda_ineq)):\n            lambda_ineq[i] = max(0, lambda_ineq[i] + mu * g[i])\n        \n        # Check convergence\n        constraint_violation = np.maximum(0, -g).sum()\n        if constraint_violation < 1e-6:\n            break\n        \n        # Increase penalty parameter\n        if mu < mu_max:\n            mu = min(mu * mu_factor, mu_max)\n    \n    # Final refinement with direct constraint optimization\n    def objective(x):\n        _, radii = unpack_variables(x)\n        return -np.sum(radii)\n    \n    def constraint_funcs(x):\n        return compute_constraints(x)\n    \n    constraints = {'type': 'ineq', 'fun': constraint_funcs}\n    \n    result_final = minimize(\n        fun=objective,\n        x0=x_current,\n        method='SLSQP',\n        bounds=[(0, 1)]*(2*n) + [(0, 0.5)]*n,\n        constraints=constraints,\n        options={'maxiter': 1000, 'ftol': 1e-10}\n    )\n    \n    centers, radii = unpack_variables(result_final.x)\n    sum_radii = np.sum(radii)\n    \n    return centers, radii, sum_radii\n\ndef run_packing():\n    \"\"\"Entry point called by evaluator.\"\"\"\n    return construct_packing()\n```",
  "reasoning": "",
  "timestamp": "2025-12-16T18:14:12.316576",
  "cost_data": null
}