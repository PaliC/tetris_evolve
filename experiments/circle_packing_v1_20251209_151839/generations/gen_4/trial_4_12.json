{
  "trial_id": "trial_4_12",
  "generation": 4,
  "parent_id": "trial_3_3",
  "code": "import numpy as np\nfrom scipy.optimize import minimize, differential_evolution\nfrom scipy.spatial.distance import cdist\n\ndef construct_packing():\n    \"\"\"\n    Construct a circle packing for n=26 circles in a unit square.\n    Uses momentum-based optimization starting from trial_3_3 solution.\n\n    Returns:\n        centers: np.array of shape (26, 2) - (x, y) coordinates of circle centers\n        radii: np.array of shape (26,) - radius of each circle\n        sum_radii: float - sum of all radii\n    \"\"\"\n    n = 26\n    \n    # First, run trial_3_3 approach to get a good starting point\n    def trial_3_3_solution():\n        \"\"\"Generate initial solution using grid + optimization approach\"\"\"\n        # Start with 5x5 grid plus 1 extra circle\n        grid_size = 5\n        spacing = 1.0 / (grid_size + 1)\n        \n        centers = []\n        for i in range(grid_size):\n            for j in range(grid_size):\n                x = spacing * (i + 1)\n                y = spacing * (j + 1)\n                centers.append([x, y])\n        \n        # Add one more circle at a strategic position\n        centers.append([0.5, 0.5])\n        centers = np.array(centers[:n])\n        \n        # Initial uniform radii\n        radii = np.full(n, 0.08)\n        \n        # Optimize with differential evolution\n        def objective(x):\n            c = x[:2*n].reshape(n, 2)\n            r = x[2*n:]\n            \n            # Penalize constraint violations\n            penalty = 0.0\n            \n            # Boundary constraints\n            for i in range(n):\n                if c[i, 0] - r[i] < 0:\n                    penalty += (0 - (c[i, 0] - r[i])) * 100\n                if c[i, 0] + r[i] > 1:\n                    penalty += (c[i, 0] + r[i] - 1) * 100\n                if c[i, 1] - r[i] < 0:\n                    penalty += (0 - (c[i, 1] - r[i])) * 100\n                if c[i, 1] + r[i] > 1:\n                    penalty += (c[i, 1] + r[i] - 1) * 100\n            \n            # Non-overlap constraints\n            dists = cdist(c, c)\n            for i in range(n):\n                for j in range(i+1, n):\n                    overlap = r[i] + r[j] - dists[i, j]\n                    if overlap > 0:\n                        penalty += overlap * 100\n            \n            # Negative radii penalty\n            for i in range(n):\n                if r[i] < 0:\n                    penalty += -r[i] * 100\n            \n            return -np.sum(r) + penalty\n        \n        x0 = np.concatenate([centers.flatten(), radii])\n        bounds = [(0, 1)] * (2*n) + [(0, 0.5)] * n\n        \n        result = differential_evolution(\n            objective, \n            bounds, \n            maxiter=300,\n            popsize=15,\n            seed=42,\n            atol=1e-6,\n            tol=1e-6\n        )\n        \n        best_x = result.x\n        best_centers = best_x[:2*n].reshape(n, 2)\n        best_radii = best_x[2*n:]\n        \n        return best_centers, best_radii\n    \n    # Get initial solution from trial_3_3\n    centers, radii = trial_3_3_solution()\n    \n    # Now apply momentum-based optimization\n    def compute_gradient(x, epsilon=1e-6):\n        \"\"\"Compute gradient using finite differences\"\"\"\n        grad = np.zeros_like(x)\n        f0 = objective_with_penalty(x)\n        \n        for i in range(len(x)):\n            x_plus = x.copy()\n            x_plus[i] += epsilon\n            f_plus = objective_with_penalty(x_plus)\n            grad[i] = (f_plus - f0) / epsilon\n        \n        return grad\n    \n    def objective_with_penalty(x):\n        \"\"\"Objective with smooth penalty for constraints\"\"\"\n        c = x[:2*n].reshape(n, 2)\n        r = x[2*n:]\n        \n        penalty = 0.0\n        \n        # Boundary constraints with smooth penalty\n        for i in range(n):\n            penalty += max(0, -(c[i, 0] - r[i]))**2 * 1000\n            penalty += max(0, c[i, 0] + r[i] - 1)**2 * 1000\n            penalty += max(0, -(c[i, 1] - r[i]))**2 * 1000\n            penalty += max(0, c[i, 1] + r[i] - 1)**2 * 1000\n            penalty += max(0, -r[i])**2 * 1000\n        \n        # Non-overlap constraints\n        dists = cdist(c, c)\n        for i in range(n):\n            for j in range(i+1, n):\n                overlap = r[i] + r[j] - dists[i, j]\n                if overlap > 0:\n                    penalty += overlap**2 * 1000\n        \n        return -np.sum(r) + penalty\n    \n    def project_to_feasible(x):\n        \"\"\"Project solution to feasible region\"\"\"\n        c = x[:2*n].reshape(n, 2)\n        r = x[2*n:]\n        \n        # Clip centers and radii to bounds\n        for i in range(n):\n            # Ensure radii are non-negative\n            r[i] = max(0, r[i])\n            \n            # Ensure circles fit in square\n            max_r = min(c[i, 0], 1 - c[i, 0], c[i, 1], 1 - c[i, 1])\n            r[i] = min(r[i], max_r)\n            \n            # Clip centers\n            c[i, 0] = np.clip(c[i, 0], r[i], 1 - r[i])\n            c[i, 1] = np.clip(c[i, 1], r[i], 1 - r[i])\n        \n        return np.concatenate([c.flatten(), r])\n    \n    # Momentum optimization\n    x = np.concatenate([centers.flatten(), radii])\n    velocity = np.zeros_like(x)\n    beta = 0.9  # Momentum coefficient\n    learning_rate = 0.001\n    best_x = x.copy()\n    best_obj = objective_with_penalty(x)\n    \n    for iteration in range(1000):\n        # Compute gradient\n        grad = compute_gradient(x, epsilon=1e-7)\n        \n        # Update velocity with momentum\n        velocity = beta * velocity - learning_rate * grad\n        \n        # Update position\n        x_new = x + velocity\n        \n        # Project to feasible region\n        x_new = project_to_feasible(x_new)\n        \n        # Evaluate\n        obj_new = objective_with_penalty(x_new)\n        \n        # Accept if better\n        if obj_new < best_obj:\n            best_obj = obj_new\n            best_x = x_new.copy()\n            x = x_new\n            # Increase learning rate on success\n            learning_rate = min(learning_rate * 1.05, 0.01)\n        else:\n            # Decrease learning rate on failure\n            learning_rate *= 0.95\n            # Reset velocity\n            velocity *= 0.5\n        \n        # Adaptive restart\n        if iteration % 100 == 0 and iteration > 0:\n            x = best_x.copy()\n            velocity = np.zeros_like(x)\n            learning_rate = 0.001\n    \n    # Final polish with SLSQP\n    def objective_final(x):\n        r = x[2*n:]\n        return -np.sum(r)\n    \n    def constraint_boundary(x):\n        c = x[:2*n].reshape(n, 2)\n        r = x[2*n:]\n        violations = []\n        for i in range(n):\n            violations.append(c[i, 0] - r[i])\n            violations.append(1 - c[i, 0] - r[i])\n            violations.append(c[i, 1] - r[i])\n            violations.append(1 - c[i, 1] - r[i])\n        return np.array(violations)\n    \n    def constraint_overlap(x):\n        c = x[:2*n].reshape(n, 2)\n        r = x[2*n:]\n        dists = cdist(c, c)\n        violations = []\n        for i in range(n):\n            for j in range(i+1, n):\n                violations.append(dists[i, j] - r[i] - r[j])\n        return np.array(violations)\n    \n    constraints = [\n        {'type': 'ineq', 'fun': constraint_boundary},\n        {'type': 'ineq', 'fun': constraint_overlap},\n        {'type': 'ineq', 'fun': lambda x: x[2*n:]}  # radii >= 0\n    ]\n    \n    bounds = [(0, 1)] * (2*n) + [(0, 0.5)] * n\n    \n    result = minimize(\n        objective_final,\n        best_x,\n        method='SLSQP',\n        bounds=bounds,\n        constraints=constraints,\n        options={'maxiter': 500, 'ftol': 1e-9}\n    )\n    \n    if result.success:\n        best_x = result.x\n    \n    # Extract final solution\n    final_centers = best_x[:2*n].reshape(n, 2)\n    final_radii = best_x[2*n:]\n    sum_radii = np.sum(final_radii)\n    \n    return final_centers, final_radii, sum_radii\n\ndef run_packing():\n    \"\"\"Entry point called by evaluator.\"\"\"\n    return construct_packing()",
  "metrics": {
    "valid": true,
    "sum_radii": 2.5928457231784146,
    "target_ratio": 0.9840021719842181,
    "combined_score": 0.9840021719842181,
    "eval_time": 54.630277156829834,
    "error": null
  },
  "prompt": "Momentum-based optimization.\n\nBased on trial_3_3 with momentum refinement:\n1. Run trial_3_3 to get best solution\n2. Apply gradient descent with momentum:\n   - Compute gradient numerically (finite differences)\n   - Update with momentum term (\u03b2=0.9)\n   - Adaptive learning rate\n3. Project back to feasible region after each step\n4. Run for 1000 iterations\n5. Final SLSQP polish with tight tolerances\n\nInclude construct_packing() and run_packing() functions.",
  "response": "```python\nimport numpy as np\nfrom scipy.optimize import minimize, differential_evolution\nfrom scipy.spatial.distance import cdist\n\ndef construct_packing():\n    \"\"\"\n    Construct a circle packing for n=26 circles in a unit square.\n    Uses momentum-based optimization starting from trial_3_3 solution.\n\n    Returns:\n        centers: np.array of shape (26, 2) - (x, y) coordinates of circle centers\n        radii: np.array of shape (26,) - radius of each circle\n        sum_radii: float - sum of all radii\n    \"\"\"\n    n = 26\n    \n    # First, run trial_3_3 approach to get a good starting point\n    def trial_3_3_solution():\n        \"\"\"Generate initial solution using grid + optimization approach\"\"\"\n        # Start with 5x5 grid plus 1 extra circle\n        grid_size = 5\n        spacing = 1.0 / (grid_size + 1)\n        \n        centers = []\n        for i in range(grid_size):\n            for j in range(grid_size):\n                x = spacing * (i + 1)\n                y = spacing * (j + 1)\n                centers.append([x, y])\n        \n        # Add one more circle at a strategic position\n        centers.append([0.5, 0.5])\n        centers = np.array(centers[:n])\n        \n        # Initial uniform radii\n        radii = np.full(n, 0.08)\n        \n        # Optimize with differential evolution\n        def objective(x):\n            c = x[:2*n].reshape(n, 2)\n            r = x[2*n:]\n            \n            # Penalize constraint violations\n            penalty = 0.0\n            \n            # Boundary constraints\n            for i in range(n):\n                if c[i, 0] - r[i] < 0:\n                    penalty += (0 - (c[i, 0] - r[i])) * 100\n                if c[i, 0] + r[i] > 1:\n                    penalty += (c[i, 0] + r[i] - 1) * 100\n                if c[i, 1] - r[i] < 0:\n                    penalty += (0 - (c[i, 1] - r[i])) * 100\n                if c[i, 1] + r[i] > 1:\n                    penalty += (c[i, 1] + r[i] - 1) * 100\n            \n            # Non-overlap constraints\n            dists = cdist(c, c)\n            for i in range(n):\n                for j in range(i+1, n):\n                    overlap = r[i] + r[j] - dists[i, j]\n                    if overlap > 0:\n                        penalty += overlap * 100\n            \n            # Negative radii penalty\n            for i in range(n):\n                if r[i] < 0:\n                    penalty += -r[i] * 100\n            \n            return -np.sum(r) + penalty\n        \n        x0 = np.concatenate([centers.flatten(), radii])\n        bounds = [(0, 1)] * (2*n) + [(0, 0.5)] * n\n        \n        result = differential_evolution(\n            objective, \n            bounds, \n            maxiter=300,\n            popsize=15,\n            seed=42,\n            atol=1e-6,\n            tol=1e-6\n        )\n        \n        best_x = result.x\n        best_centers = best_x[:2*n].reshape(n, 2)\n        best_radii = best_x[2*n:]\n        \n        return best_centers, best_radii\n    \n    # Get initial solution from trial_3_3\n    centers, radii = trial_3_3_solution()\n    \n    # Now apply momentum-based optimization\n    def compute_gradient(x, epsilon=1e-6):\n        \"\"\"Compute gradient using finite differences\"\"\"\n        grad = np.zeros_like(x)\n        f0 = objective_with_penalty(x)\n        \n        for i in range(len(x)):\n            x_plus = x.copy()\n            x_plus[i] += epsilon\n            f_plus = objective_with_penalty(x_plus)\n            grad[i] = (f_plus - f0) / epsilon\n        \n        return grad\n    \n    def objective_with_penalty(x):\n        \"\"\"Objective with smooth penalty for constraints\"\"\"\n        c = x[:2*n].reshape(n, 2)\n        r = x[2*n:]\n        \n        penalty = 0.0\n        \n        # Boundary constraints with smooth penalty\n        for i in range(n):\n            penalty += max(0, -(c[i, 0] - r[i]))**2 * 1000\n            penalty += max(0, c[i, 0] + r[i] - 1)**2 * 1000\n            penalty += max(0, -(c[i, 1] - r[i]))**2 * 1000\n            penalty += max(0, c[i, 1] + r[i] - 1)**2 * 1000\n            penalty += max(0, -r[i])**2 * 1000\n        \n        # Non-overlap constraints\n        dists = cdist(c, c)\n        for i in range(n):\n            for j in range(i+1, n):\n                overlap = r[i] + r[j] - dists[i, j]\n                if overlap > 0:\n                    penalty += overlap**2 * 1000\n        \n        return -np.sum(r) + penalty\n    \n    def project_to_feasible(x):\n        \"\"\"Project solution to feasible region\"\"\"\n        c = x[:2*n].reshape(n, 2)\n        r = x[2*n:]\n        \n        # Clip centers and radii to bounds\n        for i in range(n):\n            # Ensure radii are non-negative\n            r[i] = max(0, r[i])\n            \n            # Ensure circles fit in square\n            max_r = min(c[i, 0], 1 - c[i, 0], c[i, 1], 1 - c[i, 1])\n            r[i] = min(r[i], max_r)\n            \n            # Clip centers\n            c[i, 0] = np.clip(c[i, 0], r[i], 1 - r[i])\n            c[i, 1] = np.clip(c[i, 1], r[i], 1 - r[i])\n        \n        return np.concatenate([c.flatten(), r])\n    \n    # Momentum optimization\n    x = np.concatenate([centers.flatten(), radii])\n    velocity = np.zeros_like(x)\n    beta = 0.9  # Momentum coefficient\n    learning_rate = 0.001\n    best_x = x.copy()\n    best_obj = objective_with_penalty(x)\n    \n    for iteration in range(1000):\n        # Compute gradient\n        grad = compute_gradient(x, epsilon=1e-7)\n        \n        # Update velocity with momentum\n        velocity = beta * velocity - learning_rate * grad\n        \n        # Update position\n        x_new = x + velocity\n        \n        # Project to feasible region\n        x_new = project_to_feasible(x_new)\n        \n        # Evaluate\n        obj_new = objective_with_penalty(x_new)\n        \n        # Accept if better\n        if obj_new < best_obj:\n            best_obj = obj_new\n            best_x = x_new.copy()\n            x = x_new\n            # Increase learning rate on success\n            learning_rate = min(learning_rate * 1.05, 0.01)\n        else:\n            # Decrease learning rate on failure\n            learning_rate *= 0.95\n            # Reset velocity\n            velocity *= 0.5\n        \n        # Adaptive restart\n        if iteration % 100 == 0 and iteration > 0:\n            x = best_x.copy()\n            velocity = np.zeros_like(x)\n            learning_rate = 0.001\n    \n    # Final polish with SLSQP\n    def objective_final(x):\n        r = x[2*n:]\n        return -np.sum(r)\n    \n    def constraint_boundary(x):\n        c = x[:2*n].reshape(n, 2)\n        r = x[2*n:]\n        violations = []\n        for i in range(n):\n            violations.append(c[i, 0] - r[i])\n            violations.append(1 - c[i, 0] - r[i])\n            violations.append(c[i, 1] - r[i])\n            violations.append(1 - c[i, 1] - r[i])\n        return np.array(violations)\n    \n    def constraint_overlap(x):\n        c = x[:2*n].reshape(n, 2)\n        r = x[2*n:]\n        dists = cdist(c, c)\n        violations = []\n        for i in range(n):\n            for j in range(i+1, n):\n                violations.append(dists[i, j] - r[i] - r[j])\n        return np.array(violations)\n    \n    constraints = [\n        {'type': 'ineq', 'fun': constraint_boundary},\n        {'type': 'ineq', 'fun': constraint_overlap},\n        {'type': 'ineq', 'fun': lambda x: x[2*n:]}  # radii >= 0\n    ]\n    \n    bounds = [(0, 1)] * (2*n) + [(0, 0.5)] * n\n    \n    result = minimize(\n        objective_final,\n        best_x,\n        method='SLSQP',\n        bounds=bounds,\n        constraints=constraints,\n        options={'maxiter': 500, 'ftol': 1e-9}\n    )\n    \n    if result.success:\n        best_x = result.x\n    \n    # Extract final solution\n    final_centers = best_x[:2*n].reshape(n, 2)\n    final_radii = best_x[2*n:]\n    sum_radii = np.sum(final_radii)\n    \n    return final_centers, final_radii, sum_radii\n\ndef run_packing():\n    \"\"\"Entry point called by evaluator.\"\"\"\n    return construct_packing()\n```",
  "reasoning": "",
  "timestamp": "2025-12-09T15:51:51.947182",
  "cost_data": null
}